{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "from heterogeneous_spatial_networks_funcs import filepath_str, filename_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may or may not correspond to the number of cpus for optimal\n",
    "# parallelization performance. Feel free to modify if you see fit.\n",
    "cpu_num = int(np.floor(multiprocessing.cpu_count()/2))\n",
    "\n",
    "# Initialization of identification information for this particular batch\n",
    "# of spider web-inspired Delaunay-triangulated networks\n",
    "date = \"20240812\"\n",
    "batch = \"A\"\n",
    "network = \"auelp\"\n",
    "scheme = \"rccs\"\n",
    "\n",
    "date_str = f\"date_{date}\"\n",
    "batch_str = f\"batch_{batch}\"\n",
    "network_str = f\"network_{network}\"\n",
    "scheme_str = f\"scheme_{scheme}\"\n",
    "\n",
    "dim_str = \"dim\"\n",
    "b_str = \"b\"\n",
    "xi_str = \"xi\"\n",
    "rho_nu_str = \"rho_nu\"\n",
    "k_str = \"k\"\n",
    "n_str = \"n\"\n",
    "nu_str = \"nu\"\n",
    "config_str = \"config\"\n",
    "\n",
    "filepath = filepath_str(network)\n",
    "filename_prefix = filepath + f\"{date}{batch}\"\n",
    "\n",
    "identifier_filename = filename_prefix + \"-identifier\" + \".txt\"\n",
    "dim_filename = filename_prefix + f\"-{dim_str}\" + \".dat\"\n",
    "b_filename = filename_prefix + f\"-{b_str}\" + \".dat\"\n",
    "xi_filename = filename_prefix + f\"-{xi_str}\" + \".dat\"\n",
    "rho_nu_filename = filename_prefix + f\"-{rho_nu_str}\" + \".dat\"\n",
    "k_filename = filename_prefix + f\"-{k_str}\" + \".dat\"\n",
    "n_filename = filename_prefix + f\"-{n_str}\" + \".dat\"\n",
    "nu_filename = filename_prefix + f\"-{nu_str}\" + \".dat\"\n",
    "config_filename = filename_prefix + f\"-{config_str}\" + \".dat\"\n",
    "params_filename = filename_prefix + \"-params\" + \".dat\"\n",
    "sample_params_filename = filename_prefix + \"-sample_params\" + \".dat\"\n",
    "sample_config_params_filename = (\n",
    "    filename_prefix + \"-sample_config_params\" + \".dat\"\n",
    ")\n",
    "\n",
    "identifier_arr = np.asarray(\n",
    "    [date_str, batch_str, network_str, scheme_str, dim_str, b_str, xi_str,\n",
    "     rho_nu_str, k_str, n_str, nu_str])\n",
    "\n",
    "# Initialization of fundamental parameters for polydisperse artificial\n",
    "# end-linked polymer networks\n",
    "dim_arr = np.asarray([2], dtype=int) # np.asarray([2, 3], dtype=int)\n",
    "b_arr = np.asarray([1.0])\n",
    "xi_arr = np.asarray([0.98])\n",
    "rho_nu_arr = np.asarray([0.85])\n",
    "k_arr = np.asarray([4], dtype=int) # np.arange(3, 9, dtype=int) # 3, 4, 5, 6, 7, 8\n",
    "n_arr = np.asarray([150], dtype=int) # np.asarray([100, 150, 224, 334, 500, 748, 1118, 1672, 2500], dtype=int) # = np.rint(np.logspace(np.log10(100), np.log10(2500), num=9)).astype(int)\n",
    "nu_arr = np.asarray([25], dtype=int) # np.asarray([5, 25, 125, 525], dtype=int)\n",
    "config_arr = np.asarray([0], dtype=int) # 0 # np.arange(5, dtype=int) # 0, 1, 2, 3, 4\n",
    "\n",
    "dim_num = np.shape(dim_arr)[0]\n",
    "b_num = np.shape(b_arr)[0]\n",
    "xi_num = np.shape(xi_arr)[0]\n",
    "rho_nu_num = np.shape(rho_nu_arr)[0]\n",
    "k_num = np.shape(k_arr)[0]\n",
    "n_num = np.shape(n_arr)[0]\n",
    "nu_num = np.shape(nu_arr)[0]\n",
    "config_num = np.shape(config_arr)[0]\n",
    "\n",
    "sample_num = dim_num * b_num * xi_num * rho_nu_num * k_num * n_num * nu_num\n",
    "sample_config_num = sample_num * config_num\n",
    "\n",
    "# Populate the network parameters array\n",
    "params_arr = np.empty([sample_num, 7])\n",
    "sample = 0\n",
    "for dim in np.nditer(dim_arr):\n",
    "    for b in np.nditer(b_arr):\n",
    "        for xi in np.nditer(xi_arr):\n",
    "            for rho_nu in np.nditer(rho_nu_arr):\n",
    "                for k in np.nditer(k_arr):\n",
    "                    for n in np.nditer(n_arr):\n",
    "                        for nu in np.nditer(nu_arr):        \n",
    "                            params_arr[sample, :] = (\n",
    "                                np.asarray([dim, b, xi, rho_nu, k, n, nu])\n",
    "                            )\n",
    "                            sample += 1\n",
    "\n",
    "# Populate the network sample parameters array\n",
    "sample_params_arr = np.empty([sample_num, 8])\n",
    "sample = 0\n",
    "for dim in np.nditer(dim_arr):\n",
    "    for b in np.nditer(b_arr):\n",
    "        for xi in np.nditer(xi_arr):\n",
    "            for rho_nu in np.nditer(rho_nu_arr):\n",
    "                for k in np.nditer(k_arr):\n",
    "                    for n in np.nditer(n_arr):\n",
    "                        for nu in np.nditer(nu_arr):\n",
    "                            sample_params_arr[sample, :] = (\n",
    "                                np.asarray([sample, dim, b, xi, rho_nu, k, n, nu])\n",
    "                            )\n",
    "                            sample += 1\n",
    "\n",
    "# Populate the network sample configuration parameters array\n",
    "sample_config_params_arr = np.empty([sample_config_num, 9])\n",
    "sample = 0\n",
    "indx = 0\n",
    "for dim in np.nditer(dim_arr):\n",
    "    for b in np.nditer(b_arr):\n",
    "        for xi in np.nditer(xi_arr):\n",
    "            for rho_nu in np.nditer(rho_nu_arr):\n",
    "                for k in np.nditer(k_arr):\n",
    "                    for n in np.nditer(n_arr):\n",
    "                        for nu in np.nditer(nu_arr):\n",
    "                            for config in np.nditer(config_arr):\n",
    "                                sample_config_params_arr[indx, :] = (\n",
    "                                    np.asarray([sample, dim, b, xi, rho_nu, k, n, nu, config])\n",
    "                                )\n",
    "                                indx += 1\n",
    "                            sample += 1\n",
    "\n",
    "# Save identification information and fundamental network parameters\n",
    "np.savetxt(identifier_filename, identifier_arr, fmt=\"%s\")\n",
    "np.savetxt(dim_filename, dim_arr, fmt=\"%d\")\n",
    "np.savetxt(b_filename, b_arr)\n",
    "np.savetxt(xi_filename, xi_arr)\n",
    "np.savetxt(rho_nu_filename, rho_nu_arr)\n",
    "np.savetxt(k_filename, k_arr, fmt=\"%d\")\n",
    "np.savetxt(n_filename, n_arr, fmt=\"%d\")\n",
    "np.savetxt(nu_filename, nu_arr, fmt=\"%d\")\n",
    "np.savetxt(config_filename, config_arr, fmt=\"%d\")\n",
    "np.savetxt(params_filename, params_arr)\n",
    "np.savetxt(sample_params_filename, sample_params_arr)\n",
    "np.savetxt(sample_config_params_filename, sample_config_params_arr)\n",
    "\n",
    "sample = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and save L for the auelp parameter sample -- properly functionalize and parallelize this in the near future\n",
    "from heterogeneous_spatial_networks_funcs import m_arg_stoich_func, n_nu_arg_m_func, L_arg_rho_func\n",
    "\n",
    "# Generate filename\n",
    "L_filename = filename_str(network, date, batch, sample) + \"-L\" + \".dat\"\n",
    "\n",
    "# Calculate L\n",
    "dim = dim_arr[0]\n",
    "rho_nu = rho_nu_arr[0]\n",
    "k = k_arr[0]\n",
    "n = n_arr[0]\n",
    "nu = nu_arr[0]\n",
    "m = m_arg_stoich_func(n, k)\n",
    "n_nu = n_nu_arg_m_func(m, nu)\n",
    "L = L_arg_rho_func(dim, n_nu, rho_nu)\n",
    "\n",
    "# Save L\n",
    "np.savetxt(L_filename, [L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the random cross-linker seeding procedure for the auelp parameter sample -- properly functionalize and parallelize this in the near future\\\n",
    "from heterogeneous_spatial_networks_funcs import crosslinker_seeding\n",
    "\n",
    "max_try = 100\n",
    "\n",
    "dim = dim_arr[0]\n",
    "b = b_arr[0]\n",
    "n = n_arr[0]\n",
    "config = config_arr[0]\n",
    "\n",
    "crosslinker_seeding(network, date, batch, sample, scheme, dim, b, n, config, max_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if the number of cross-linkers seeded in the random\n",
    "# cross-linker procedure, rccs_n, equals the intended/specified number\n",
    "# of cross-linkers to be seeded, n. Continue to the topology\n",
    "# initialization procedure ONLY IF rccs_n = n. If rccs_n != n for any\n",
    "# specified network, then the code block identifies which particular\n",
    "# set(s) of network parameters rccs_n != n occurred for.\n",
    "rccs_filename = (\n",
    "    filename_str(network, date, batch, sample)\n",
    "    + f\"C{config:d}\" + \".config\"\n",
    ")\n",
    "rccs = np.loadtxt(rccs_filename)\n",
    "\n",
    "if np.shape(rccs)[0] == n:\n",
    "    print_str = (\n",
    "        \"Success! rccs_n = n from the random core cross-linker seeding \"\n",
    "        + \"procedure for all network parameters!\"\n",
    "    )\n",
    "    print(print_str)\n",
    "else: \n",
    "    print_str = (\n",
    "        \"rccs_n != n from the random core cross-linker seeding \"\n",
    "        + \"procedure for at least one set of network parameters. \"\n",
    "        + \"Repeat the random core cross-linker seeding procedure \"\n",
    "        + \"for the applicable set of network parameters before \"\n",
    "        + \"continuing on to the topology initialization procedure.\"\n",
    "    )\n",
    "    print(print_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testbed for the auelp_dim_2_simple_network_topology_initialization\n",
    "# Args:\n",
    "# L (float): Simulation box size of the core cross-linkers.\n",
    "# core_x (np.ndarray): x-coordinates of the core cross-linkers.\n",
    "# core_y (np.ndarray): y-coordinates of the core cross-linkers.\n",
    "# b (float): Chain segment and/or cross-linker diameter.\n",
    "# xi (float): Chain-to-cross-link connection probability\n",
    "# n (float): Number of core cross-linkers.\n",
    "# m (float): Number of chains.\n",
    "# nu (float): Number of segments in each chain.\n",
    "# k (int): Maximum cross-linker degree/functionality.\n",
    "# max_try (int): \n",
    "# filename (str): Baseline filename for data files.\n",
    "\n",
    "# Precalculation that should happen before calling the function\n",
    "from heterogeneous_spatial_networks_funcs import m_arg_stoich_func\n",
    "\n",
    "# Generate filename\n",
    "filename = filename_str(network, date, batch, sample)\n",
    "L_filename = filename + \"-L\" + \".dat\"\n",
    "\n",
    "# Load L\n",
    "L = np.loadtxt(L_filename)\n",
    "\n",
    "# Append configuration number to filename\n",
    "filename = filename + f\"C{config:d}\"\n",
    "\n",
    "# Generate config filename\n",
    "config_filename = filename + \".config\"\n",
    "\n",
    "# Load core cross-linker coordinates\n",
    "rccs = np.loadtxt(config_filename)\n",
    "# Actual number of core cross-linkers\n",
    "n = np.shape(rccs)[0] # rccs_n = np.shape(rccs)[0]\n",
    "# Separate x- and y-coordinates of core cross-linkers\n",
    "core_x = rccs[:, 0].copy() # rccs_x = rccs[:, 0].copy()\n",
    "core_y = rccs[:, 1].copy() # rccs_y = rccs[:, 1].copy()\n",
    "\n",
    "b = b_arr[0]\n",
    "xi = xi_arr[0]\n",
    "k = k_arr[0]\n",
    "nu = nu_arr[0]\n",
    "m = m_arg_stoich_func(n, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the actual function, apply an int(np.floor()) to various parameters, as a fail-safe check\n",
    "n = int(np.floor(n))\n",
    "m = int(np.floor(m))\n",
    "nu = int(np.floor(nu))\n",
    "k = int(np.floor(k))\n",
    "max_try = int(np.floor(max_try))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine r_nghbrhd\n",
    "r_nghbrhd = 0.\n",
    "r_mic = L / 2.\n",
    "l_cntr = nu * b\n",
    "\n",
    "if l_cntr > r_mic:\n",
    "    r_nghbrhd = r_mic\n",
    "else:\n",
    "    r_nghbrhd = l_cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Brief aside: plot the Gaussian distribution\n",
    "# from heterogeneous_spatial_networks_funcs import p_gaussian_cnfrmtn_func\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# r_arr = np.linspace(0, l_cntr, 101)\n",
    "# p_cnfrmtn_arr = p_gaussian_cnfrmtn_func(b, nu, r_arr)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.plot(r_arr, p_cnfrmtn_arr, \"*-\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the relative polymer chain conformation probability density via protocol from Hanson\n",
    "\n",
    "from heterogeneous_spatial_networks_funcs import p_gaussian_cnfrmtn_func, ln_p_cnfrmtn_cubic_poly_fit_func\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Be careful with exactly how the binning -- or bin placement -- is defined\n",
    "r_arr = np.linspace(0, r_nghbrhd, 101)\n",
    "\n",
    "p_cnfrmtn_arr = p_gaussian_cnfrmtn_func(b, nu, r_arr)\n",
    "ln_p_cnfrmtn_arr = np.log(p_cnfrmtn_arr) # natural log\n",
    "\n",
    "popt, pconv = optimize.curve_fit(ln_p_cnfrmtn_cubic_poly_fit_func, r_arr, ln_p_cnfrmtn_arr)\n",
    "\n",
    "ln_p_cnfrmtn_cubic_poly_fit_arr = ln_p_cnfrmtn_cubic_poly_fit_func(r_arr, *popt)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(r_arr, ln_p_cnfrmtn_arr, \"*-\", color=\"blue\")\n",
    "plt.plot(r_arr, ln_p_cnfrmtn_cubic_poly_fit_arr, \"-\", color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dnglng_chns = np.linspace(0, r_nghbrhd, 1001)\n",
    "# Calculate and normalize weighting factors\n",
    "w_dnglng_chns = np.exp(\n",
    "    ln_p_cnfrmtn_cubic_poly_fit_func(r_dnglng_chns, *popt))\n",
    "w_dnglng_chns = w_dnglng_chns / np.sum(w_dnglng_chns, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tessellate cross-linkers\n",
    "\n",
    "from heterogeneous_spatial_networks_funcs import tessellation_protocol, dim_2_tessellation\n",
    "\n",
    "# Copy the core_x and core_y np.ndarrays as the first n entries in\n",
    "# the tessellated cross-linker x- and y-coordinate np.ndarrays\n",
    "tsslltd_core_x = core_x.copy()\n",
    "tsslltd_core_y = core_y.copy()\n",
    "\n",
    "# Two-dimensional tessellation protocol\n",
    "dim_2_tsslltn, dim_2_tsslltn_num = tessellation_protocol(2)\n",
    "    \n",
    "# Use two-dimensional tessellation protocol to tessellate the core\n",
    "# cross-linkers\n",
    "for tsslltn in range(dim_2_tsslltn_num):\n",
    "    x_tsslltn = dim_2_tsslltn[tsslltn, 0]\n",
    "    y_tsslltn = dim_2_tsslltn[tsslltn, 1]\n",
    "    # Skip the (hold, hold) tessellation call because the core\n",
    "    # cross-linkers are being tessellated about themselves\n",
    "    if (x_tsslltn == 0) and (y_tsslltn == 0): continue\n",
    "    else:\n",
    "        # x- and y-coordinates from two-dimensional tessellation\n",
    "        # protocol\n",
    "        core_tsslltn_x, core_tsslltn_y = (\n",
    "            dim_2_tessellation(L, core_x, core_y, x_tsslltn, y_tsslltn)\n",
    "        )\n",
    "        # Concatenate the tessellated x- and y-coordinates\n",
    "        tsslltd_core_x = np.concatenate((tsslltd_core_x, core_tsslltn_x))\n",
    "        tsslltd_core_y = np.concatenate((tsslltd_core_y, core_tsslltn_y))\n",
    "\n",
    "del core_tsslltn_x, core_tsslltn_y\n",
    "\n",
    "# Identify core nodes as cross-linkers\n",
    "core_node_type = np.ones(n, dtype=int)\n",
    "\n",
    "# Core cross-linker nodes\n",
    "core_nodes = np.arange(n, dtype=int)\n",
    "\n",
    "# Construct the pb2core_nodes np.ndarray such that\n",
    "# pb2core_nodes[core_pb_node] = core_node\n",
    "pb2core_nodes = np.tile(core_nodes, dim_2_tsslltn_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sampling neighborhoods for each core cross-linker\n",
    "\n",
    "from heterogeneous_spatial_networks_funcs import core2pb_nodes_func\n",
    "\n",
    "# Initialize sampling neighborhood list\n",
    "core_nodes_nghbrhd = []\n",
    "r_core_nodes_nghbrhd = []\n",
    "\n",
    "for core_node in np.nditer(core_nodes):\n",
    "    core_node = int(core_node)\n",
    "    core_node_x = tsslltd_core_x[core_node]\n",
    "    core_node_y = tsslltd_core_y[core_node]\n",
    "    core_node_pstn = np.asarray(\n",
    "        [\n",
    "            core_node_x,\n",
    "            core_node_y\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Downselect the local square neighborhood that is \\pm r_nghbrhd\n",
    "    # about the core node. Start by gathering the tessellated\n",
    "    # cross-linker nodes that meet this criterion in each separate\n",
    "    # coordinate.\n",
    "    lcl_nghbr_x_lb = core_node_x - r_nghbrhd\n",
    "    lcl_nghbr_x_ub = core_node_x + r_nghbrhd\n",
    "    lcl_nghbr_y_lb = core_node_y - r_nghbrhd\n",
    "    lcl_nghbr_y_ub = core_node_y + r_nghbrhd\n",
    "    psbl_lcl_nghbr_x_nodes = (\n",
    "        np.where(np.logical_and(tsslltd_core_x>=lcl_nghbr_x_lb, tsslltd_core_x<=lcl_nghbr_x_ub))[0]\n",
    "    )\n",
    "    psbl_lcl_nghbr_y_nodes = (\n",
    "        np.where(np.logical_and(tsslltd_core_y>=lcl_nghbr_y_lb, tsslltd_core_y<=lcl_nghbr_y_ub))[0]\n",
    "    )\n",
    "    # Gather the nodes from each separate coordinate together to\n",
    "    # assess all possible local cross-linker neighbors. Retain unique\n",
    "    # possible local cross-linker neighbor nodes, and the number of\n",
    "    # times each such node appears\n",
    "    psbl_lcl_nghbr_nodes, psbl_lcl_nghbr_nodes_counts = (\n",
    "        np.unique(np.concatenate((psbl_lcl_nghbr_x_nodes, psbl_lcl_nghbr_y_nodes), dtype=int), return_counts=True)\n",
    "    )\n",
    "    # The true local cross-linker neighbor nodes are those who appear\n",
    "    # twice in the possible cross-linker neighbor node array -- equal to\n",
    "    # the network dimensionality\n",
    "    lcl_nghbr_nodes_indcs = np.where(psbl_lcl_nghbr_nodes_counts == 2)[0]\n",
    "    lcl_nghbr_node_num = np.shape(lcl_nghbr_nodes_indcs)[0]\n",
    "    # Further downselect to the neighborhood of tessellated\n",
    "    # cross-linker nodes that are a distance of r_nghbrhd away from the\n",
    "    # core node\n",
    "    if lcl_nghbr_node_num > 0:\n",
    "        # Gather the indices of the local cross-linker neighbors\n",
    "        lcl_nghbr_nodes = psbl_lcl_nghbr_nodes[lcl_nghbr_nodes_indcs]\n",
    "        # Extract local cross-linker neighbor coordinates\n",
    "        lcl_nghbr_x = tsslltd_core_x[lcl_nghbr_nodes]\n",
    "        lcl_nghbr_y = tsslltd_core_y[lcl_nghbr_nodes]\n",
    "        # Calculate the distance between the core node and the local\n",
    "        # cross-linker neighbor nodes\n",
    "        r_lcl_nghbr_nodes = np.empty(lcl_nghbr_node_num)\n",
    "        for lcl_nghbr_node_indx in range(lcl_nghbr_node_num):\n",
    "            lcl_nghbr_pstn = np.asarray(\n",
    "                [\n",
    "                    lcl_nghbr_x[lcl_nghbr_node_indx],\n",
    "                    lcl_nghbr_y[lcl_nghbr_node_indx]\n",
    "                ]\n",
    "            )\n",
    "            r_lcl_nghbr_nodes[lcl_nghbr_node_indx] = (\n",
    "                np.linalg.norm(core_node_pstn-lcl_nghbr_pstn)\n",
    "            )\n",
    "        # The true cross-linker neighbor nodes are those whose distance\n",
    "        # to the core node is less than r_nghbrhd\n",
    "        nghbr_nodes_indcs = np.where(r_lcl_nghbr_nodes <= r_nghbrhd)[0]\n",
    "        nghbr_nodes = lcl_nghbr_nodes[nghbr_nodes_indcs]\n",
    "        r_nghbr_nodes = r_lcl_nghbr_nodes[nghbr_nodes_indcs]\n",
    "        # Add the cross-linker neighbor nodes array to the sampling\n",
    "        # neighborhood list\n",
    "        core_nodes_nghbrhd.append(nghbr_nodes)\n",
    "        r_core_nodes_nghbrhd.append(r_nghbr_nodes)\n",
    "    else:\n",
    "        core_nodes_nghbrhd.append(np.asarray([]))\n",
    "        r_core_nodes_nghbrhd.append(np.asarray([]))\n",
    "\n",
    "# Retain unique nodes from the core and periodic boundary cross-linkers\n",
    "# in the sampling neighborhood list\n",
    "core_pb_nodes = np.unique(\n",
    "    np.concatenate(tuple(nghbrhd for nghbrhd in core_nodes_nghbrhd), dtype=int))\n",
    "\n",
    "# Extract the core and periodic boundary cross-linker x- and\n",
    "# y-coordinates using the corresponding node numbers\n",
    "core_pb_x = tsslltd_core_x[core_pb_nodes].copy()\n",
    "core_pb_y = tsslltd_core_y[core_pb_nodes].copy()\n",
    "\n",
    "del tsslltd_core_x, tsslltd_core_y\n",
    "\n",
    "# Extract the core and periodic boundary cross-linker nodes in the\n",
    "# np.ndarray that returns the core cross-linker node that corresponds to\n",
    "# each core and periodic boundary cross-linker node\n",
    "pb2core_nodes = pb2core_nodes[core_pb_nodes].copy()\n",
    "\n",
    "# Refactor the node numbers in the sampling neighborhood list\n",
    "for core_node in np.nditer(core_nodes):\n",
    "    core_node = int(core_node)\n",
    "    nghbr_nodes = core_nodes_nghbrhd[core_node]\n",
    "    for nghbr_node_indx in range(np.shape(nghbr_nodes)[0]):\n",
    "        nghbr_nodes[nghbr_node_indx] = (\n",
    "            int(np.where(core_pb_nodes == nghbr_nodes[nghbr_node_indx])[0][0])\n",
    "        )\n",
    "    core_nodes_nghbrhd[core_node] = nghbr_nodes\n",
    "\n",
    "# Extract the number of core and periodic boundary cross-linker nodes\n",
    "core_pb_n = np.shape(core_pb_nodes)[0]\n",
    "\n",
    "# Refactor core_pb_nodes\n",
    "core_pb_nodes = np.arange(core_pb_n, dtype=int)\n",
    "# Define core_pb_conn_nodes\n",
    "core_pb_conn_nodes = core_nodes.copy()\n",
    "\n",
    "# Extract the number of periodic boundary cross-linker nodes\n",
    "pb_n = core_pb_n - n\n",
    "\n",
    "# Identify periodic boundary nodes as cross-linkers\n",
    "pb_node_type = np.ones(pb_n, dtype=int)\n",
    "\n",
    "# Periodic boundary cross-linker nodes\n",
    "pb_nodes = n + np.arange(pb_n, dtype=int)\n",
    "\n",
    "# Extract the periodic boundary cross-linker x- and y-coordinates using\n",
    "# the periodic boundary node numbers\n",
    "pb_x = core_pb_x[pb_nodes]\n",
    "pb_y = core_pb_y[pb_nodes]\n",
    "\n",
    "# Extract the periodic node entries of pb2core_nodes\n",
    "pb_nodes_pb2core_nodes = pb2core_nodes[pb_nodes]\n",
    "\n",
    "# Construct the core2pb_nodes list\n",
    "core2pb_nodes = core2pb_nodes_func(core_nodes, pb2core_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preformatting continued\n",
    "\n",
    "# Note that for multi-chain edges and self-loop chains, the graph object\n",
    "# will provide that information on-demand\n",
    "\n",
    "# Anti-degree of the core cross-linker nodes\n",
    "core_nodes_anti_k = k*np.ones(n, dtype=int)\n",
    "# Core cross-linker node active sites\n",
    "core_nodes_active_sites = np.repeat(core_nodes, k)\n",
    "core_nodes_active_sites_num = np.shape(core_nodes_active_sites)[0]\n",
    "\n",
    "# Cross-linker node coordinates for dangling chains\n",
    "core_pb_dnglng_chns_x = core_pb_x.copy()\n",
    "core_pb_dnglng_chns_y = core_pb_y.copy()\n",
    "\n",
    "# Free end node coordinates for dangling chains\n",
    "core_dnglng_chns_x = []\n",
    "core_dnglng_chns_y = []\n",
    "pb_dnglng_chns_x = []\n",
    "pb_dnglng_chns_y = []\n",
    "\n",
    "# Initialize edge lists\n",
    "core_pb_conn_edges = [] # list of tuples\n",
    "core_pb_edges = [] # list of lists\n",
    "core_pb_conn_dnglng_edges = [] # [[core_node_original, core_node_dnglng_chain]]\n",
    "core_dnglng_edges = [] # [[core_node_original, core_node_dnglng_chain]]\n",
    "core_pb_dnglng_edges = [] # [[core_node_original, pb_node_dnglng_chain]]\n",
    "core_dnglng_pb_edges = [] # [[core_node_dnglng_chain, pb_node_original]]\n",
    "pb_nodes_pb2core_nodes_dnglng_edges = [] # [core_node_dnglng_chain (for a given pb_node_dnglng_chain)]\n",
    "\n",
    "# Initialize node number integer constants\n",
    "core_node_0 = 0\n",
    "core_node_1 = 0\n",
    "pb_node_0 = 0\n",
    "pb_node_1 = 0\n",
    "core_node_dnglng_chns_n = -1 # Python is zero-indexed, this will be >= 0 (0, 1, 2, 3, etc.)\n",
    "pb_node_dnglng_chns_n = -1 # Python is zero-indexed, this will be >= 0 (0, 1, 2, 3, etc.)\n",
    "\n",
    "# Initialize number of chains and number of dangling chains in the\n",
    "# network\n",
    "# m_dnglng = 0\n",
    "# Initialize number of chains in the network\n",
    "m_ntwk = 0\n",
    "\n",
    "# Initialize random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 598 -1 -1\n",
      "2 596 -1 -1\n",
      "3 594 -1 -1\n",
      "4 592 -1 -1\n",
      "5 590 -1 -1\n",
      "6 588 -1 -1\n",
      "7 586 -1 -1\n",
      "8 584 -1 -1\n",
      "9 582 -1 -1\n",
      "10 580 -1 -1\n",
      "11 578 -1 -1\n",
      "12 576 -1 -1\n",
      "13 575 0 -1\n",
      "14 573 0 -1\n",
      "15 571 0 -1\n",
      "16 569 0 -1\n",
      "17 567 0 -1\n",
      "18 565 0 -1\n",
      "19 563 0 -1\n",
      "20 561 0 -1\n",
      "21 559 0 -1\n",
      "22 557 0 -1\n",
      "23 555 0 -1\n",
      "24 553 0 -1\n",
      "25 551 0 -1\n",
      "26 549 0 -1\n",
      "27 547 0 -1\n",
      "28 545 0 -1\n",
      "29 543 0 -1\n",
      "30 541 0 -1\n",
      "31 539 0 -1\n",
      "32 537 0 -1\n",
      "33 535 0 -1\n",
      "34 533 0 -1\n",
      "35 532 1 -1\n",
      "36 530 1 -1\n",
      "37 528 1 -1\n",
      "38 526 1 -1\n",
      "39 524 1 -1\n",
      "40 522 1 -1\n",
      "41 520 1 -1\n",
      "42 518 1 -1\n",
      "43 516 1 -1\n",
      "44 514 1 -1\n",
      "45 512 1 -1\n",
      "46 510 1 -1\n",
      "47 508 1 -1\n",
      "48 506 1 -1\n",
      "49 504 1 -1\n",
      "50 502 1 -1\n",
      "51 500 1 -1\n",
      "52 498 1 -1\n",
      "53 496 1 -1\n",
      "54 494 1 -1\n",
      "55 492 1 -1\n",
      "56 490 1 -1\n",
      "57 488 1 -1\n",
      "58 486 1 -1\n",
      "59 484 1 -1\n",
      "60 482 1 -1\n",
      "61 480 1 -1\n",
      "62 478 1 -1\n",
      "63 476 1 -1\n",
      "64 474 1 -1\n",
      "65 472 1 -1\n",
      "66 470 1 -1\n",
      "67 468 1 -1\n",
      "68 466 1 -1\n",
      "69 464 1 -1\n",
      "70 462 1 -1\n",
      "71 460 1 -1\n",
      "72 458 1 -1\n",
      "73 456 1 -1\n",
      "74 454 1 -1\n",
      "75 452 1 -1\n",
      "76 450 1 -1\n",
      "77 448 1 -1\n",
      "78 446 1 -1\n",
      "79 444 1 -1\n",
      "80 442 1 -1\n",
      "81 440 1 -1\n",
      "82 438 1 -1\n",
      "83 436 1 -1\n",
      "84 434 1 -1\n",
      "85 432 1 -1\n",
      "86 430 1 -1\n",
      "87 428 1 -1\n",
      "88 426 1 -1\n",
      "89 424 1 -1\n",
      "90 422 1 -1\n",
      "91 420 1 -1\n",
      "92 418 1 -1\n",
      "93 416 1 -1\n",
      "94 414 1 -1\n",
      "95 412 1 -1\n",
      "96 410 1 -1\n",
      "97 408 1 -1\n",
      "98 406 1 -1\n",
      "99 404 1 -1\n",
      "100 402 1 -1\n",
      "101 400 1 -1\n",
      "102 398 1 -1\n",
      "103 396 1 -1\n",
      "104 394 1 -1\n",
      "105 392 1 -1\n",
      "106 390 1 -1\n",
      "107 388 1 -1\n",
      "108 386 1 -1\n",
      "109 384 1 -1\n",
      "110 382 1 -1\n",
      "111 380 1 -1\n",
      "112 378 1 -1\n",
      "113 376 1 -1\n",
      "114 374 1 -1\n",
      "115 372 1 -1\n",
      "116 370 1 -1\n",
      "117 368 1 -1\n",
      "118 366 1 -1\n",
      "119 364 1 -1\n",
      "120 362 1 -1\n",
      "121 360 1 -1\n",
      "122 358 1 -1\n",
      "123 356 1 -1\n",
      "124 354 1 -1\n",
      "125 352 1 -1\n",
      "126 350 1 -1\n",
      "127 348 1 -1\n",
      "128 346 1 -1\n",
      "129 344 1 -1\n",
      "130 342 1 -1\n",
      "131 340 1 -1\n",
      "132 338 1 -1\n",
      "133 336 1 -1\n",
      "134 334 1 -1\n",
      "135 332 1 -1\n",
      "136 330 1 -1\n",
      "137 328 1 -1\n",
      "138 326 1 -1\n",
      "139 324 1 -1\n",
      "140 322 1 -1\n",
      "141 320 1 -1\n",
      "142 318 1 -1\n",
      "143 316 1 -1\n",
      "144 314 1 -1\n",
      "145 312 1 -1\n",
      "146 310 1 -1\n",
      "147 308 1 -1\n",
      "148 306 1 -1\n",
      "149 304 1 -1\n",
      "150 302 1 -1\n",
      "151 301 2 -1\n",
      "152 299 2 -1\n",
      "153 297 2 -1\n",
      "154 295 2 -1\n",
      "155 293 2 -1\n",
      "156 291 2 -1\n",
      "157 289 2 -1\n",
      "158 287 2 -1\n",
      "159 285 2 -1\n",
      "160 283 2 -1\n",
      "161 281 2 -1\n",
      "162 279 2 -1\n",
      "163 277 2 -1\n",
      "164 275 2 -1\n",
      "165 273 2 -1\n",
      "166 271 2 -1\n",
      "167 269 2 -1\n",
      "168 267 2 -1\n",
      "169 265 2 -1\n",
      "170 263 2 -1\n",
      "171 261 2 -1\n",
      "172 259 2 -1\n",
      "173 257 2 -1\n",
      "174 255 2 -1\n",
      "175 253 2 -1\n",
      "176 251 2 -1\n",
      "177 250 3 -1\n",
      "178 248 3 -1\n",
      "179 246 3 -1\n",
      "180 244 3 -1\n",
      "181 242 3 -1\n",
      "182 240 3 -1\n",
      "183 238 3 -1\n",
      "184 236 3 -1\n",
      "185 234 3 -1\n",
      "186 233 4 -1\n",
      "187 231 4 -1\n",
      "188 229 4 -1\n",
      "189 227 4 -1\n",
      "190 225 4 -1\n",
      "191 223 4 -1\n",
      "192 221 4 -1\n",
      "193 219 4 -1\n",
      "194 217 4 -1\n",
      "195 215 4 -1\n",
      "196 213 4 -1\n",
      "197 211 4 -1\n",
      "198 209 4 -1\n",
      "199 207 4 -1\n",
      "200 205 4 -1\n",
      "201 203 4 -1\n",
      "202 201 4 -1\n",
      "203 199 4 -1\n",
      "204 197 4 -1\n",
      "205 195 4 -1\n",
      "206 193 4 -1\n",
      "207 191 4 -1\n",
      "208 189 4 -1\n",
      "209 187 4 -1\n",
      "210 185 4 -1\n",
      "211 183 4 -1\n",
      "212 181 4 -1\n",
      "213 179 4 -1\n",
      "214 177 4 -1\n",
      "215 175 4 -1\n",
      "216 173 4 -1\n",
      "217 171 4 -1\n",
      "218 169 4 -1\n",
      "219 167 4 -1\n",
      "220 165 4 -1\n",
      "221 163 4 -1\n",
      "222 161 4 -1\n",
      "223 159 4 -1\n",
      "224 157 4 -1\n",
      "225 155 4 -1\n",
      "226 153 4 -1\n",
      "227 151 4 -1\n",
      "228 149 4 -1\n",
      "229 147 4 -1\n",
      "230 145 4 -1\n",
      "231 143 4 -1\n",
      "232 141 4 -1\n",
      "233 139 4 -1\n",
      "234 137 4 -1\n",
      "235 135 4 -1\n",
      "236 133 4 -1\n",
      "237 131 4 -1\n",
      "238 129 4 -1\n",
      "239 127 4 -1\n",
      "240 125 4 -1\n",
      "241 123 4 -1\n",
      "242 121 4 -1\n",
      "243 119 4 -1\n",
      "244 117 4 -1\n",
      "245 115 4 -1\n",
      "246 113 4 -1\n",
      "247 111 4 -1\n",
      "248 109 4 -1\n",
      "249 107 4 -1\n",
      "250 105 4 -1\n",
      "251 103 4 -1\n",
      "252 101 4 -1\n",
      "253 99 4 -1\n",
      "254 97 4 -1\n",
      "255 95 4 -1\n",
      "256 93 4 -1\n",
      "257 91 4 -1\n",
      "258 89 4 -1\n",
      "259 87 4 -1\n",
      "260 85 4 -1\n",
      "261 83 4 -1\n",
      "262 81 4 -1\n",
      "263 79 4 -1\n",
      "264 77 4 -1\n",
      "265 75 4 -1\n",
      "266 73 4 -1\n",
      "267 71 4 -1\n",
      "268 69 4 -1\n",
      "269 67 4 -1\n",
      "270 65 4 -1\n",
      "271 63 4 -1\n",
      "272 61 4 -1\n",
      "273 59 4 -1\n",
      "274 57 4 -1\n",
      "275 56 5 -1\n",
      "276 54 5 -1\n",
      "277 52 5 -1\n",
      "278 50 5 -1\n",
      "279 48 5 -1\n",
      "280 46 5 -1\n",
      "281 44 5 -1\n",
      "282 42 5 -1\n",
      "283 40 5 -1\n",
      "284 38 5 -1\n",
      "285 36 5 -1\n",
      "286 34 5 -1\n",
      "287 32 5 -1\n",
      "288 30 5 -1\n",
      "289 28 5 -1\n",
      "290 26 5 -1\n",
      "291 24 5 -1\n",
      "292 22 5 -1\n",
      "293 20 5 -1\n",
      "294 18 5 -1\n",
      "295 16 5 -1\n",
      "296 14 5 -1\n",
      "297 12 5 -1\n",
      "298 10 5 -1\n",
      "299 8 5 -1\n",
      "300 6 5 -1\n"
     ]
    }
   ],
   "source": [
    "# Network topology initialization continues until either (1) all of the\n",
    "# chains have been placed, i.e., m_ntwk = m, or (2) there are no more\n",
    "# active sites, i.e., core_nodes_active_sites_num = 0\n",
    "\n",
    "def core_node_update_func(\n",
    "        core_node_updt: int,\n",
    "        core_node_updt_active_site_indx: int,\n",
    "        core_nodes_active_sites: np.ndarray,\n",
    "        core_nodes_active_sites_num: int,\n",
    "        core_nodes_anti_k: np.ndarray,\n",
    "        core_nodes: np.ndarray,\n",
    "        core2pb_nodes: list[np.ndarray],\n",
    "        core_nodes_nghbrhd: list[np.ndarray],\n",
    "        r_core_nodes_nghbrhd: list[np.ndarray]) -> tuple[np.ndarray, int, np.ndarray, np.ndarray, list[np.ndarray], list[np.ndarray]]:\n",
    "    # Update inactive sites\n",
    "    core_nodes_active_sites = np.delete(\n",
    "        core_nodes_active_sites, core_node_updt_active_site_indx, axis=0)\n",
    "    core_nodes_active_sites_num -= 1\n",
    "    # Update anti-degree\n",
    "    core_nodes_anti_k[core_node_updt] -= 1\n",
    "    # Update sampling neighborhood list if the core cross-linker node\n",
    "    # now has no more active sites\n",
    "    if core_nodes_anti_k[core_node_updt] == 0:\n",
    "        # Update sampling neighborhood list\n",
    "        # Gather associated periodic boundary nodes\n",
    "        pb_nodes_updt = core2pb_nodes[core_node_updt]\n",
    "        for core_node in np.nditer(core_nodes):\n",
    "            core_node = int(core_node)\n",
    "            nghbr_nodes = core_nodes_nghbrhd[core_node]\n",
    "            r_nghbr_nodes = r_core_nodes_nghbrhd[core_node]\n",
    "            if np.shape(nghbr_nodes)[0] == 0: pass\n",
    "            else:\n",
    "                # Address core node\n",
    "                core_node_updt_indx_arr = np.where(nghbr_nodes == core_node_updt)[0]\n",
    "                if np.shape(core_node_updt_indx_arr)[0] == 0: pass\n",
    "                else:\n",
    "                    core_node_updt_indx = int(core_node_updt_indx_arr[0])\n",
    "                    nghbr_nodes = np.delete(nghbr_nodes, core_node_updt_indx, axis=0)\n",
    "                    r_nghbr_nodes = np.delete(r_nghbr_nodes, core_node_updt_indx, axis=0)\n",
    "                # Address all associated periodic boundary nodes\n",
    "                if np.shape(pb_nodes_updt)[0] == 0: pass\n",
    "                else:\n",
    "                    for pb_node_updt in np.nditer(pb_nodes_updt):\n",
    "                        pb_node_updt = int(pb_node_updt)\n",
    "                        pb_node_updt_indx_arr = np.where(nghbr_nodes == pb_node_updt)[0]\n",
    "                        if np.shape(pb_node_updt_indx_arr)[0] == 0: pass\n",
    "                        else:\n",
    "                            pb_node_updt_indx = int(pb_node_updt_indx_arr[0])\n",
    "                            nghbr_nodes = np.delete(nghbr_nodes, pb_node_updt_indx, axis=0)\n",
    "                            r_nghbr_nodes = np.delete(r_nghbr_nodes, pb_node_updt_indx, axis=0)\n",
    "                core_nodes_nghbrhd[core_node] = nghbr_nodes\n",
    "                r_core_nodes_nghbrhd[core_node] = r_nghbr_nodes\n",
    "    \n",
    "    return (\n",
    "        core_nodes_active_sites, core_nodes_active_sites_num, core_nodes_anti_k,\n",
    "        core_nodes_nghbrhd, r_core_nodes_nghbrhd\n",
    "    )\n",
    "\n",
    "def dangling_chains_update_func(\n",
    "        core_node_updt: int,\n",
    "        max_try: int,\n",
    "        rng: np.random.Generator,\n",
    "        r_dnglng_chns: np.ndarray,\n",
    "        w_dnglng_chns: np.ndarray,\n",
    "        b: float,\n",
    "        L: float,\n",
    "        core2pb_nodes: list[np.ndarray],\n",
    "        core_node_dnglng_chns_n: int,\n",
    "        pb_node_dnglng_chns_n: int,\n",
    "        core_pb_conn_dnglng_edges: list[list[int, int]],\n",
    "        core_dnglng_edges: list[list[int, int]],\n",
    "        core_pb_dnglng_edges: list[list[int, int]],\n",
    "        core_dnglng_pb_edges: list[list[int, int]],\n",
    "        pb_nodes_pb2core_nodes_dnglng_edges: list[int],\n",
    "        core_dnglng_chns_x: list[float],\n",
    "        core_dnglng_chns_y: list[float],\n",
    "        pb_dnglng_chns_x: list[float],\n",
    "        pb_dnglng_chns_y: list[float],\n",
    "        core_pb_dnglng_chns_x: np.ndarray,\n",
    "        core_pb_dnglng_chns_y: np.ndarray):\n",
    "    from heterogeneous_spatial_networks_funcs import (\n",
    "        tessellation_protocol,\n",
    "        dim_2_tessellation_protocol\n",
    "    )\n",
    "    \n",
    "    # Two-dimensional tessellation protocol\n",
    "    dim_2_tsslltn, dim_2_tsslltn_num = tessellation_protocol(2)\n",
    "    \n",
    "    # Begin dangling chain update procedure\n",
    "    num_try = 0\n",
    "\n",
    "    while num_try < max_try:\n",
    "        # Isotropically place a candidate node representing the free end\n",
    "        # of the dangling chain\n",
    "        node_dnglng_chn_cnddt_x = core_pb_dnglng_chns_x[core_node_updt]\n",
    "        node_dnglng_chn_cnddt_y = core_pb_dnglng_chns_y[core_node_updt]\n",
    "        theta = 2 * np.pi * rng.uniform()\n",
    "        r = rng.choice(r_dnglng_chns, size=None, p=w_dnglng_chns)\n",
    "        node_dnglng_chn_cnddt_x += r * np.cos(theta)\n",
    "        node_dnglng_chn_cnddt_y += r * np.sin(theta)\n",
    "        node_dnglng_chn_cnddt = np.asarray(\n",
    "            [\n",
    "                node_dnglng_chn_cnddt_x,\n",
    "                node_dnglng_chn_cnddt_y\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Downselect the previously-generated nodes to those that reside\n",
    "        # in a local square neighborhood that is \\pm b about the free\n",
    "        # end candidate. Start by gathering the indices of nodes that\n",
    "        # meet this criterion in each separate coordinate\n",
    "        nghbr_x_lb = node_dnglng_chn_cnddt_x - b\n",
    "        nghbr_x_ub = node_dnglng_chn_cnddt_x + b\n",
    "        nghbr_y_lb = node_dnglng_chn_cnddt_y - b\n",
    "        nghbr_y_ub = node_dnglng_chn_cnddt_y + b\n",
    "        psbl_nghbr_x_indcs = (\n",
    "            np.where(np.logical_and(core_pb_dnglng_chns_x>=nghbr_x_lb, core_pb_dnglng_chns_x<=nghbr_x_ub))[0]\n",
    "        )\n",
    "        psbl_nghbr_y_indcs = (\n",
    "            np.where(np.logical_and(core_pb_dnglng_chns_y>=nghbr_y_lb, core_pb_dnglng_chns_y<=nghbr_y_ub))[0]\n",
    "        )\n",
    "        # Gather the indices from each separate coordinate together to\n",
    "        # assess all possible neighbors\n",
    "        psbl_nghbr_indcs = (\n",
    "            np.concatenate((psbl_nghbr_x_indcs, psbl_nghbr_y_indcs))\n",
    "        )\n",
    "        # Retain unique indices corresponding to each possible neighbor,\n",
    "        # and the number of times each such index value appears\n",
    "        psbl_nghbr_indcs, psbl_nghbr_indcs_counts = (\n",
    "            np.unique(psbl_nghbr_indcs, return_counts=True)\n",
    "        )\n",
    "        # The true neighbors are those whose index value appears twice\n",
    "        # in the possible neighbor array -- equal to the network\n",
    "        # dimensionality\n",
    "        nghbr_indcs_vals_indcs = np.where(psbl_nghbr_indcs_counts == 2)[0]\n",
    "        nghbr_num = np.shape(nghbr_indcs_vals_indcs)[0]\n",
    "        # Continue analysis if a local neighborhood actually exists\n",
    "        # about the candidate\n",
    "        if nghbr_num > 0:\n",
    "            # Gather the indices of the neighbors\n",
    "            nghbr_indcs = psbl_nghbr_indcs[nghbr_indcs_vals_indcs]\n",
    "            # Extract neighbor coordinates\n",
    "            nghbr_x = core_pb_dnglng_chns_x[nghbr_indcs]\n",
    "            nghbr_y = core_pb_dnglng_chns_y[nghbr_indcs]\n",
    "            \n",
    "            # Calculate the minimum distance between the candidate and\n",
    "            # its neighbors\n",
    "            dist = np.empty(nghbr_num)\n",
    "            for nghbr_indx in range(nghbr_num):\n",
    "                nghbr = np.asarray(\n",
    "                    [\n",
    "                        nghbr_x[nghbr_indx],\n",
    "                        nghbr_y[nghbr_indx]\n",
    "                    ]\n",
    "                )\n",
    "                dist[nghbr_indx] = np.linalg.norm(node_dnglng_chn_cnddt-nghbr)\n",
    "            min_dist = np.min(dist)\n",
    "\n",
    "            # Try again if the minimum distance between the candidate\n",
    "            # and its neighbors is less than b\n",
    "            if min_dist < b:\n",
    "                num_try += 1\n",
    "                continue\n",
    "        \n",
    "        # Accept and tessellate the candidate if (1) no local\n",
    "        # neighborhood exists about the candidate, or (2) the minimum\n",
    "        # distance between the candidate and its neighbors is greater\n",
    "        # than or equal to b. At this point, check to see if the\n",
    "        # candidate node representing the free end of the dangling chain\n",
    "        # is a core node or a periodic boundary node.\n",
    "        # Free end is a core node\n",
    "        if (0<=node_dnglng_chn_cnddt_x<L) and (0<=node_dnglng_chn_cnddt_y<L):\n",
    "            # Isolate coordinates of the dangling chain core node\n",
    "            core_node_dnglng_chn_x = node_dnglng_chn_cnddt_x\n",
    "            core_node_dnglng_chn_y = node_dnglng_chn_cnddt_y\n",
    "            # Increase dangling chain core node number\n",
    "            core_node_dnglng_chns_n += 1\n",
    "            # Add to edge lists\n",
    "            core_pb_conn_dnglng_edges.append([core_node_updt, core_node_dnglng_chns_n])\n",
    "            core_dnglng_edges.append([core_node_updt, core_node_dnglng_chns_n])\n",
    "            # Add coordinates to coordinate lists\n",
    "            core_dnglng_chns_x.append(core_node_dnglng_chn_x)\n",
    "            core_dnglng_chns_y.append(core_node_dnglng_chn_y)\n",
    "            # Use two-dimensional tessellation protocol to tessellate\n",
    "            # the accepted candidate core node\n",
    "            node_dnglng_chn_tsslltn_x, node_dnglng_chn_tsslltn_y = (\n",
    "                dim_2_tessellation_protocol(\n",
    "                    L, core_node_dnglng_chn_x, core_node_dnglng_chn_y,\n",
    "                    dim_2_tsslltn)\n",
    "            )\n",
    "            \n",
    "            core_pb_dnglng_chns_x = (\n",
    "                np.concatenate((core_pb_dnglng_chns_x, node_dnglng_chn_tsslltn_x))\n",
    "            )\n",
    "            core_pb_dnglng_chns_y = (\n",
    "                np.concatenate((core_pb_dnglng_chns_y, node_dnglng_chn_tsslltn_y))\n",
    "            )\n",
    "        # Free end is a periodic boundary node\n",
    "        else:\n",
    "            # Isolate coordinates of the free end periodic boundary node\n",
    "            pb_node_dnglng_chn_x = node_dnglng_chn_cnddt_x\n",
    "            pb_node_dnglng_chn_y = node_dnglng_chn_cnddt_y\n",
    "            # Determine the free end core node coordinates that\n",
    "            # correspond to the free end periodic boundary node via the\n",
    "            # minimum image criterion\n",
    "            core_node_dnglng_chn_x = 0.0\n",
    "            core_node_dnglng_chn_y = 0.0\n",
    "            if pb_node_dnglng_chn_x < 0:\n",
    "                core_node_dnglng_chn_x = pb_node_dnglng_chn_x + L\n",
    "            elif pb_node_dnglng_chn_x >= 0:\n",
    "                core_node_dnglng_chn_x = pb_node_dnglng_chn_x - L\n",
    "            if pb_node_dnglng_chn_y < 0:\n",
    "                core_node_dnglng_chn_y = pb_node_dnglng_chn_y + L\n",
    "            elif pb_node_dnglng_chn_y >= 0:\n",
    "                core_node_dnglng_chn_y = pb_node_dnglng_chn_y - L\n",
    "            # Determine the attached cross-linker periodic boundary node\n",
    "            # corresponding to the dangling chain via the minimum image\n",
    "            # criterion, i.e., the minimum distance criterion \n",
    "            core_node_dnglng_chn_pstn = np.asarray(\n",
    "                [\n",
    "                    core_node_dnglng_chn_x,\n",
    "                    core_node_dnglng_chn_y\n",
    "                ]\n",
    "            )\n",
    "            pb_nodes_updt = core2pb_nodes[core_node_updt]\n",
    "            pb_nodes_updt_num = np.shape(pb_nodes_updt)[0]\n",
    "            r_pb_nodes_updt = np.empty(pb_nodes_updt_num)\n",
    "            for pb_node_updt_indx in range(pb_nodes_updt_num):\n",
    "                pb_node_updt_cnddt = pb_nodes_updt[pb_node_updt_indx]\n",
    "                pb_node_updt_cnddt_pstn = np.asarray(\n",
    "                    [\n",
    "                        core_pb_dnglng_chns_x[pb_node_updt_cnddt],\n",
    "                        core_pb_dnglng_chns_y[pb_node_updt_cnddt]\n",
    "                    ]\n",
    "                )\n",
    "                r_pb_nodes_updt[pb_node_updt_indx] = (\n",
    "                    np.linalg.norm(core_node_dnglng_chn_pstn-pb_node_updt_cnddt_pstn)\n",
    "                )\n",
    "            pb_node_updt = pb_nodes_updt[np.argmin(r_pb_nodes_updt)]\n",
    "            # Increase dangling chain core and periodic boundary node\n",
    "            # numbers\n",
    "            core_node_dnglng_chns_n += 1\n",
    "            pb_node_dnglng_chns_n += 1\n",
    "            # Add to edge lists\n",
    "            core_pb_conn_dnglng_edges.append([core_node_updt, core_node_dnglng_chns_n])\n",
    "            core_pb_dnglng_edges.append([core_node_updt, pb_node_dnglng_chns_n])\n",
    "            core_dnglng_pb_edges.append([core_node_dnglng_chns_n, pb_node_updt])\n",
    "            # Add to pb_nodes_pb2core_nodes_dnglng_edges list\n",
    "            pb_nodes_pb2core_nodes_dnglng_edges.append(core_node_dnglng_chns_n)\n",
    "            # Add coordinates to coordinate lists\n",
    "            core_dnglng_chns_x.append(core_node_dnglng_chn_x)\n",
    "            core_dnglng_chns_y.append(core_node_dnglng_chn_y)\n",
    "            pb_dnglng_chns_x.append(pb_node_dnglng_chn_x)\n",
    "            pb_dnglng_chns_y.append(pb_node_dnglng_chn_y)\n",
    "            # Use two-dimensional tessellation protocol to tessellate\n",
    "            # the accepted candidate core node\n",
    "            node_dnglng_chn_tsslltn_x, node_dnglng_chn_tsslltn_y = (\n",
    "                dim_2_tessellation_protocol(\n",
    "                    L, core_node_dnglng_chn_x, core_node_dnglng_chn_y,\n",
    "                    dim_2_tsslltn)\n",
    "            )\n",
    "            \n",
    "            core_pb_dnglng_chns_x = (\n",
    "                np.concatenate((core_pb_dnglng_chns_x, node_dnglng_chn_tsslltn_x))\n",
    "            )\n",
    "            core_pb_dnglng_chns_y = (\n",
    "                np.concatenate((core_pb_dnglng_chns_y, node_dnglng_chn_tsslltn_y))\n",
    "            )\n",
    "        \n",
    "        break\n",
    "\n",
    "    if num_try == max_try:\n",
    "        # Replace this with a sys.exit(error_str)\n",
    "        error_str = (\n",
    "            \"The free end of a dangling chain was unable to be created.\"\n",
    "        )\n",
    "        print(error_str)\n",
    "\n",
    "    return (\n",
    "        core_node_dnglng_chns_n, pb_node_dnglng_chns_n,\n",
    "        core_pb_conn_dnglng_edges, core_dnglng_edges, core_pb_dnglng_edges,\n",
    "        core_dnglng_pb_edges, pb_nodes_pb2core_nodes_dnglng_edges,\n",
    "        core_dnglng_chns_x, core_dnglng_chns_y,\n",
    "        pb_dnglng_chns_x, pb_dnglng_chns_y,\n",
    "        core_pb_dnglng_chns_x, core_pb_dnglng_chns_y\n",
    "    )\n",
    "\n",
    "# Network topology initialization\n",
    "while m_ntwk < m and core_nodes_active_sites_num > 0:\n",
    "    # Assess if a chain-to-cross-link connection is forged for the\n",
    "    # parent core cross-linker node\n",
    "    if rng.random() > xi: continue\n",
    "    else:\n",
    "        # Randomly select an active site from the core nodes to\n",
    "        # instantiate a chain\n",
    "        core_node_0_active_site_indx = (\n",
    "            rng.integers(np.shape(core_nodes_active_sites)[0], dtype=int)\n",
    "        )\n",
    "        core_node_0 = core_nodes_active_sites[core_node_0_active_site_indx]\n",
    "        # Update inactive sites, anti-degree, active core cross-linker\n",
    "        # nodes, and the sampling neighborhood list for the parent core\n",
    "        # cross-linker node\n",
    "        (core_nodes_active_sites, core_nodes_active_sites_num, core_nodes_anti_k,\n",
    "         core_nodes_nghbrhd, r_core_nodes_nghbrhd) = core_node_update_func(\n",
    "             core_node_0, core_node_0_active_site_indx, core_nodes_active_sites,\n",
    "             core_nodes_active_sites_num, core_nodes_anti_k, core_nodes,\n",
    "             core2pb_nodes, core_nodes_nghbrhd, r_core_nodes_nghbrhd)\n",
    "        # Assess if a chain-to-cross-link connection is forged for a\n",
    "        # neighbor cross-linker node\n",
    "        if rng.random() > xi:\n",
    "            # A dangling chain is formed\n",
    "            (core_node_dnglng_chns_n, pb_node_dnglng_chns_n,\n",
    "             core_pb_conn_dnglng_edges, core_dnglng_edges, core_pb_dnglng_edges,\n",
    "             core_dnglng_pb_edges, pb_nodes_pb2core_nodes_dnglng_edges,\n",
    "             core_dnglng_chns_x, core_dnglng_chns_y,\n",
    "             pb_dnglng_chns_x, pb_dnglng_chns_y,\n",
    "             core_pb_dnglng_chns_x, core_pb_dnglng_chns_y) = dangling_chains_update_func(\n",
    "                core_node_0, max_try, rng, r_dnglng_chns, w_dnglng_chns, b, L,\n",
    "                core2pb_nodes, core_node_dnglng_chns_n, pb_node_dnglng_chns_n,\n",
    "                core_pb_conn_dnglng_edges, core_dnglng_edges,\n",
    "                core_pb_dnglng_edges, core_dnglng_pb_edges,\n",
    "                pb_nodes_pb2core_nodes_dnglng_edges,\n",
    "                core_dnglng_chns_x, core_dnglng_chns_y,\n",
    "                pb_dnglng_chns_x, pb_dnglng_chns_y,\n",
    "                core_pb_dnglng_chns_x, core_pb_dnglng_chns_y)\n",
    "            m_ntwk += 1\n",
    "            print(m_ntwk, core_nodes_active_sites_num, core_node_dnglng_chns_n, pb_node_dnglng_chns_n)\n",
    "        else:\n",
    "            # Extract sampling neighborhood about the core node\n",
    "            nghbr_nodes = core_nodes_nghbrhd[core_node_0]\n",
    "            r_nghbr_nodes = r_core_nodes_nghbrhd[core_node_0]\n",
    "            # Check if the sampling neighborhood is empty\n",
    "            if np.shape(nghbr_nodes)[0] == 0:\n",
    "                # A dangling chain is formed\n",
    "                (core_node_dnglng_chns_n, pb_node_dnglng_chns_n,\n",
    "                core_pb_conn_dnglng_edges, core_dnglng_edges, core_pb_dnglng_edges,\n",
    "                core_dnglng_pb_edges, pb_nodes_pb2core_nodes_dnglng_edges,\n",
    "                core_dnglng_chns_x, core_dnglng_chns_y,\n",
    "                pb_dnglng_chns_x, pb_dnglng_chns_y,\n",
    "                core_pb_dnglng_chns_x, core_pb_dnglng_chns_y) = dangling_chains_update_func(\n",
    "                    core_node_0, max_try, rng, r_dnglng_chns, w_dnglng_chns, b, L,\n",
    "                    core2pb_nodes, core_node_dnglng_chns_n, pb_node_dnglng_chns_n,\n",
    "                    core_pb_conn_dnglng_edges, core_dnglng_edges,\n",
    "                    core_pb_dnglng_edges, core_dnglng_pb_edges,\n",
    "                    pb_nodes_pb2core_nodes_dnglng_edges,\n",
    "                    core_dnglng_chns_x, core_dnglng_chns_y,\n",
    "                    pb_dnglng_chns_x, pb_dnglng_chns_y,\n",
    "                    core_pb_dnglng_chns_x, core_pb_dnglng_chns_y)\n",
    "                m_ntwk += 1\n",
    "                print(m_ntwk, core_nodes_active_sites_num, core_node_dnglng_chns_n, pb_node_dnglng_chns_n)\n",
    "            else:\n",
    "                # Calculate and normalize weighting factors\n",
    "                w_nghbrhd = np.exp(\n",
    "                    ln_p_cnfrmtn_cubic_poly_fit_func(r_nghbr_nodes, *popt))\n",
    "                w_nghbrhd = w_nghbrhd / np.sum(w_nghbrhd, dtype=float)\n",
    "                # Randomly select a neighbor cross-linker node to host\n",
    "                # the other end of the chain\n",
    "                nghbr_node_1 = int(\n",
    "                    rng.choice(nghbr_nodes, size=None, p=w_nghbrhd))\n",
    "                # Identify if the chain is a core edge or a periodic\n",
    "                # boundary edge\n",
    "                # Chain is a core edge\n",
    "                if nghbr_node_1 < n:\n",
    "                    core_node_1 = nghbr_node_1\n",
    "                    # Append chain to edge lists appropriately\n",
    "                    core_pb_conn_edges.append((core_node_0, core_node_1))\n",
    "                    core_pb_edges.append([core_node_0, core_node_1])\n",
    "                # Chain is a periodic edge\n",
    "                else:\n",
    "                    pb_node_1 = nghbr_node_1\n",
    "                    core_node_1 = pb2core_nodes[pb_node_1]\n",
    "                    pb_nodes_0 = core2pb_nodes[core_node_0]\n",
    "                    # Select the correct pb_node via the minimum image\n",
    "                    # criterion, i.e., the minimum distance criterion\n",
    "                    core_node_1_pstn = np.asarray(\n",
    "                        [\n",
    "                            core_pb_x[core_node_1],\n",
    "                            core_pb_y[core_node_1]\n",
    "                        ]\n",
    "                    )\n",
    "                    pb_nodes_0_num = np.shape(pb_nodes_0)[0]\n",
    "                    r_pb_nodes_0 = np.empty(pb_nodes_0_num)\n",
    "                    for pb_node_0_indx in range(pb_nodes_0_num):\n",
    "                        pb_node_0_cnddt = pb_nodes_0[pb_node_0_indx]\n",
    "                        pb_node_0_cnddt_pstn = np.asarray(\n",
    "                            [\n",
    "                                core_pb_x[pb_node_0_cnddt],\n",
    "                                core_pb_y[pb_node_0_cnddt]\n",
    "                            ]\n",
    "                        )\n",
    "                        r_pb_nodes_0[pb_node_0_indx] = (\n",
    "                            np.linalg.norm(core_node_1_pstn-pb_node_0_cnddt_pstn)\n",
    "                        )\n",
    "                    pb_node_0 = pb_nodes_0[np.argmin(r_pb_nodes_0)]\n",
    "                    # Append chain to edge lists appropriately\n",
    "                    core_pb_conn_edges.append((core_node_0, core_node_1))\n",
    "                    core_pb_edges.append([core_node_0, pb_node_1])\n",
    "                    core_pb_edges.append([pb_node_0, core_node_1])\n",
    "                core_node_1_active_site_indx = int(\n",
    "                    np.where(core_nodes_active_sites == core_node_1)[0][0])\n",
    "                # Update inactive sites, anti-degree, active core\n",
    "                # cross-linker nodes, and the sampling neighborhood list\n",
    "                # for the neighbor core cross-linker node\n",
    "                (core_nodes_active_sites, core_nodes_active_sites_num,\n",
    "                 core_nodes_anti_k, core_nodes_nghbrhd,\n",
    "                 r_core_nodes_nghbrhd) = core_node_update_func(\n",
    "                     core_node_1, core_node_1_active_site_indx,\n",
    "                     core_nodes_active_sites, core_nodes_active_sites_num,\n",
    "                     core_nodes_anti_k, core_nodes, core2pb_nodes,\n",
    "                     core_nodes_nghbrhd, r_core_nodes_nghbrhd)\n",
    "                m_ntwk += 1\n",
    "                print(m_ntwk, core_nodes_active_sites_num, core_node_dnglng_chns_n, pb_node_dnglng_chns_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dangling chains refactor and graph creation\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# Recalibrate dangling chain node numbers\n",
    "core_node_dnglng_chns_n += 1\n",
    "pb_node_dnglng_chns_n += 1\n",
    "# Address situation where no dangling chains were added\n",
    "if core_node_dnglng_chns_n == 0:\n",
    "    # Update edge lists\n",
    "    core_pb_edges = list(tuple(edge) for edge in core_pb_edges)\n",
    "\n",
    "    # Create nx.Graphs, and add nodes before edges\n",
    "    core_pb_graph = nx.Graph()\n",
    "    core_pb_graph.add_nodes_from(core_pb_nodes)\n",
    "    core_pb_graph.add_edges_from(core_pb_edges)\n",
    "\n",
    "    core_pb_conn_graph = nx.Graph()\n",
    "    core_pb_conn_graph.add_nodes_from(core_pb_conn_nodes)\n",
    "    core_pb_conn_graph.add_edges_from(core_pb_conn_edges)\n",
    "# Address situation where only core nodes for dangling chains were added\n",
    "elif core_node_dnglng_chns_n > 0 and pb_node_dnglng_chns_n == 0:\n",
    "    # Update core node numbers in appropriate lists\n",
    "    # maybe pull these lines of code up to a higher level above\n",
    "    for edge in core_pb_conn_dnglng_edges: edge[1] += n\n",
    "    for edge in core_dnglng_edges: edge[1] += n\n",
    "    # Update periodic boundary node numbers in the core_pb_edges list\n",
    "    for edge in core_pb_edges:\n",
    "        if edge[0] >= n: edge[0] += core_node_dnglng_chns_n\n",
    "        elif edge[1] >= n: edge[1] += core_node_dnglng_chns_n\n",
    "    # Update core_pb_node_type correspondingly to end-linked network\n",
    "    # code\n",
    "    core_pb_node_type = np.concatenate(\n",
    "        (core_node_type, np.repeat(3, core_node_dnglng_chns_n), pb_node_type), dtype=int)\n",
    "    # Add core coordinates from dangling chains\n",
    "    core_pb_x = np.concatenate((core_x, np.asarray(core_dnglng_chns_x), pb_x))\n",
    "    core_pb_y = np.concatenate((core_y, np.asarray(core_dnglng_chns_y), pb_y))\n",
    "    # Update node counts\n",
    "    n += core_node_dnglng_chns_n\n",
    "    core_pb_n += core_node_dnglng_chns_n\n",
    "    # Update core_nodes, pb2core_nodes, and core2pb_nodes\n",
    "    core_nodes = np.arange(n, dtype=int)\n",
    "    pb2core_nodes = np.concatenate(\n",
    "        (core_nodes, pb_nodes_pb2core_nodes), dtype=int)\n",
    "    core2pb_nodes = core2pb_nodes_func(core_nodes, pb2core_nodes)\n",
    "    # Update core_pb_nodes and core_pb_conn_nodes\n",
    "    core_pb_nodes = np.arange(core_pb_n, dtype=int)\n",
    "    core_pb_conn_nodes = core_nodes.copy()\n",
    "    # Update edge lists\n",
    "    core_pb_edges = list(tuple(edge) for edge in core_pb_edges)\n",
    "    core_dnglng_edges = list(tuple(edge) for edge in core_dnglng_edges)\n",
    "    # core_pb_conn_edges is already modified as a list of tuples\n",
    "    core_pb_conn_dnglng_edges = list(tuple(edge) for edge in core_pb_conn_dnglng_edges)\n",
    "\n",
    "    # Create nx.Graphs, and add nodes before edges\n",
    "    core_pb_graph = nx.Graph()\n",
    "    core_pb_graph.add_nodes_from(core_pb_nodes)\n",
    "    core_pb_graph.add_edges_from(core_pb_edges)\n",
    "    core_pb_graph.add_edges_from(core_dnglng_edges)\n",
    "\n",
    "    core_pb_conn_graph = nx.Graph()\n",
    "    core_pb_conn_graph.add_nodes_from(core_pb_conn_nodes)\n",
    "    core_pb_conn_graph.add_edges_from(core_pb_conn_edges)\n",
    "    core_pb_conn_graph.add_edges_from(core_pb_conn_dnglng_edges)\n",
    "# Address situation where both core and periodic boundary nodes for\n",
    "# dangling chains were added\n",
    "else:\n",
    "    # Update core node numbers in appropriate lists\n",
    "    # maybe pull these lines of code up to a higher level above\n",
    "    for edge in core_pb_conn_dnglng_edges: edge[1] += n\n",
    "    for edge in core_dnglng_edges: edge[1] += n\n",
    "    for edge in core_dnglng_pb_edges: edge[0] += n\n",
    "    for node in pb_nodes_pb2core_nodes_dnglng_edges: node += n\n",
    "    # Update periodic boundary node numbers in appropriate lists\n",
    "    for edge in core_pb_dnglng_edges: edge[1] += core_pb_n + core_node_dnglng_chns_n\n",
    "    for edge in core_pb_edges:\n",
    "        if edge[0] >= n: edge[0] += core_node_dnglng_chns_n\n",
    "        elif edge[1] >= n: edge[1] += core_node_dnglng_chns_n\n",
    "    # Update core_pb_node_type correspondingly to end-linked network\n",
    "    # code\n",
    "    core_pb_node_type = np.concatenate(\n",
    "        (core_node_type, np.repeat(3, core_node_dnglng_chns_n), pb_node_type, np.repeat(3, pb_node_dnglng_chns_n)), dtype=int)\n",
    "    # Add core and periodic boundary coordinates from dangling chains\n",
    "    core_pb_x = np.concatenate((core_x, np.asarray(core_dnglng_chns_x), pb_x, np.asarray(pb_dnglng_chns_x)))\n",
    "    core_pb_y = np.concatenate((core_y, np.asarray(core_dnglng_chns_y), pb_y, np.asarray(pb_dnglng_chns_y)))\n",
    "    # Update node counts\n",
    "    n += core_node_dnglng_chns_n\n",
    "    core_pb_n += core_node_dnglng_chns_n + pb_node_dnglng_chns_n\n",
    "    # Update core_nodes, pb2core_nodes, and core2pb_nodes\n",
    "    core_nodes = np.arange(n, dtype=int)\n",
    "    pb2core_nodes = np.concatenate(\n",
    "        (core_nodes, pb_nodes_pb2core_nodes, np.asarray(pb_nodes_pb2core_nodes_dnglng_edges, dtype=int)), dtype=int)\n",
    "    core2pb_nodes = core2pb_nodes_func(core_nodes, pb2core_nodes)\n",
    "    # Update core_pb_nodes and core_pb_conn_nodes\n",
    "    core_pb_nodes = np.arange(core_pb_n, dtype=int)\n",
    "    core_pb_conn_nodes = core_nodes.copy()\n",
    "    # Update edge lists\n",
    "    core_pb_edges = list(tuple(edge) for edge in core_pb_edges)\n",
    "    core_dnglng_edges = list(tuple(edge) for edge in core_dnglng_edges)\n",
    "    core_pb_dnglng_edges = list(tuple(edge) for edge in core_pb_dnglng_edges)\n",
    "    core_dnglng_pb_edges = list(tuple(edge) for edge in core_dnglng_pb_edges)\n",
    "    # core_pb_conn_edges is already modified as a list of tuples\n",
    "    core_pb_conn_dnglng_edges = list(tuple(edge) for edge in core_pb_conn_dnglng_edges)\n",
    "\n",
    "    # Create nx.Graphs, and add nodes before edges\n",
    "    core_pb_graph = nx.Graph()\n",
    "    core_pb_graph.add_nodes_from(core_pb_nodes)\n",
    "    core_pb_graph.add_edges_from(core_pb_edges)\n",
    "    core_pb_graph.add_edges_from(core_dnglng_edges)\n",
    "    core_pb_graph.add_edges_from(core_pb_dnglng_edges)\n",
    "    core_pb_graph.add_edges_from(core_dnglng_pb_edges)\n",
    "\n",
    "    core_pb_conn_graph = nx.Graph()\n",
    "    core_pb_conn_graph.add_nodes_from(core_pb_conn_nodes)\n",
    "    core_pb_conn_graph.add_edges_from(core_pb_conn_edges)\n",
    "    core_pb_conn_graph.add_edges_from(core_pb_conn_dnglng_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this code chunk to isolate the core_pb_node_type array!!!\n",
    "\n",
    "# Isolate largest/maximum connected component from the\n",
    "# core_pb_conn_graph in a nodewise fashion. Note that\n",
    "# mx_cmp_core_pb_conn_graph_nodes[updated_node] = original_node\n",
    "mx_cmp_core_pb_conn_graph_nodes = max(\n",
    "    nx.connected_components(core_pb_conn_graph), key=len)\n",
    "mx_cmp_core_pb_conn_graph = (\n",
    "    core_pb_conn_graph.subgraph(mx_cmp_core_pb_conn_graph_nodes).copy()\n",
    ")\n",
    "# Nodes from the core_pb_conn_graph largest/maximum connected\n",
    "# component, sorted in ascending order\n",
    "mx_cmp_core_pb_conn_graph_nodes = (\n",
    "    np.sort(np.fromiter(mx_cmp_core_pb_conn_graph_nodes, dtype=int))\n",
    ")\n",
    "# Edges from the core_pb_conn_graph largest/maximum connected\n",
    "# component\n",
    "mx_cmp_core_pb_conn_graph_edges = (\n",
    "    np.asarray(list(mx_cmp_core_pb_conn_graph.edges()), dtype=int)\n",
    ")\n",
    "# Number of nodes in the core_pb_conn_graph largest/maximum\n",
    "# connected component\n",
    "mx_cmp_core_pb_conn_graph_n = (\n",
    "    np.shape(mx_cmp_core_pb_conn_graph_nodes)[0]\n",
    ")\n",
    "# Number of edges in the core_pb_conn_graph largest/maximum\n",
    "# connected component\n",
    "mx_cmp_core_pb_conn_graph_m = (\n",
    "    np.shape(mx_cmp_core_pb_conn_graph_edges)[0]\n",
    ")\n",
    "\n",
    "# Isolate largest/maximum connected component from the\n",
    "# core_pb_graph via the core_pb_conn_graph largest/maximum\n",
    "# connected component\n",
    "mx_cmp_core_pb_graph_nodes = []\n",
    "mx_cmp_core_pb_graph_edges = []\n",
    "\n",
    "for edge in range(mx_cmp_core_pb_conn_graph_m):\n",
    "    # original_node\n",
    "    core_node_0 = mx_cmp_core_pb_conn_graph_edges[edge, 0]\n",
    "    core_node_1 = mx_cmp_core_pb_conn_graph_edges[edge, 1]\n",
    "\n",
    "    # Add edge(s) in the core_pb_graph\n",
    "    if core_pb_graph.has_edge(core_node_0, core_node_1):\n",
    "        # Add edge that connects two core cross-linkers in the\n",
    "        # core_pb_graph, and add the core cross-linkers\n",
    "        mx_cmp_core_pb_graph_nodes.append(core_node_0)\n",
    "        mx_cmp_core_pb_graph_nodes.append(core_node_1)\n",
    "        mx_cmp_core_pb_graph_edges.append((core_node_0, core_node_1))\n",
    "    else:\n",
    "        # Add two edges that each separately yet correspondingly\n",
    "        # connect a core cross-linker and a periodic boundary\n",
    "        # cross-linker in the core_pb_graph. Also add the core\n",
    "        # and periodic boundary cross-linkers. Identify all\n",
    "        # possible periodic boundary cross-linkers that could be\n",
    "        # involved in each edge.\n",
    "        pb_nodes_0 = core2pb_nodes[core_node_0]\n",
    "        pb_nodes_1 = core2pb_nodes[core_node_1]\n",
    "        # Determine the specific periodic boundary and core\n",
    "        # cross-linker pair involved in each edge, and then add\n",
    "        # the edge and cross-linkers\n",
    "        for pb_node_0 in np.nditer(pb_nodes_0):\n",
    "            pb_node_0 = int(pb_node_0)\n",
    "            if core_pb_graph.has_edge(pb_node_0, core_node_1):\n",
    "                mx_cmp_core_pb_graph_nodes.append(pb_node_0)\n",
    "                mx_cmp_core_pb_graph_nodes.append(core_node_1)\n",
    "                mx_cmp_core_pb_graph_edges.append((pb_node_0, core_node_1))\n",
    "                break\n",
    "            else: pass\n",
    "        for pb_node_1 in np.nditer(pb_nodes_1):\n",
    "            pb_node_1 = int(pb_node_1)\n",
    "            if core_pb_graph.has_edge(core_node_0, pb_node_1):\n",
    "                mx_cmp_core_pb_graph_nodes.append(core_node_0)\n",
    "                mx_cmp_core_pb_graph_nodes.append(pb_node_1)\n",
    "                mx_cmp_core_pb_graph_edges.append((core_node_0, pb_node_1))\n",
    "                break\n",
    "            else: pass\n",
    "\n",
    "# Convert to np.ndarrays and retain unique values\n",
    "mx_cmp_core_pb_graph_nodes = (\n",
    "    np.unique(np.asarray(mx_cmp_core_pb_graph_nodes, dtype=int))\n",
    ")\n",
    "mx_cmp_core_pb_graph_edges = (\n",
    "    np.unique(np.asarray(mx_cmp_core_pb_graph_edges, dtype=int), axis=0)\n",
    ")\n",
    "# Number of nodes in the core_pb_graph largest/maximum connected\n",
    "# component\n",
    "mx_cmp_core_pb_graph_n = np.shape(mx_cmp_core_pb_graph_nodes)[0]\n",
    "# Number of edges in the core_pb_graph largest/maximum connected\n",
    "# component\n",
    "mx_cmp_core_pb_graph_m = np.shape(mx_cmp_core_pb_graph_edges)[0]\n",
    "\n",
    "# Isolate the node types for the largest/maximum connected component\n",
    "# SAVE THIS LATER!!!!!\n",
    "mx_cmp_core_pb_node_type = core_pb_node_type[mx_cmp_core_pb_graph_nodes]\n",
    "\n",
    "# Isolate the cross-linker coordinates for the largest/maximum\n",
    "# connected component\n",
    "# updated_node\n",
    "mx_cmp_core_pb_x = core_pb_x[mx_cmp_core_pb_graph_nodes]\n",
    "mx_cmp_core_pb_y = core_pb_y[mx_cmp_core_pb_graph_nodes]\n",
    "# if dim == 3:\n",
    "#     mx_cmp_core_pb_z = core_pb_z[mx_cmp_core_pb_graph_nodes]\n",
    "\n",
    "# Isolate pb2core_nodes for the largest/maximum connected\n",
    "# component. Note that\n",
    "# mx_cmp_pb2core_nodes[updated_node] = original_node\n",
    "mx_cmp_pb2core_nodes = pb2core_nodes[mx_cmp_core_pb_graph_nodes]\n",
    "\n",
    "# Update all original_node values with updated_node values for\n",
    "# mx_cmp_core_pb_conn_graph_edges\n",
    "for edge in range(mx_cmp_core_pb_conn_graph_m):\n",
    "    # updated_node\n",
    "    mx_cmp_core_pb_conn_graph_edges[edge, 0] = (\n",
    "        int(np.where(mx_cmp_core_pb_conn_graph_nodes == mx_cmp_core_pb_conn_graph_edges[edge, 0])[0][0])\n",
    "    )\n",
    "    mx_cmp_core_pb_conn_graph_edges[edge, 1] = (\n",
    "        int(np.where(mx_cmp_core_pb_conn_graph_nodes == mx_cmp_core_pb_conn_graph_edges[edge, 1])[0][0])\n",
    "    )\n",
    "\n",
    "# Update all original_node values with updated_node values for\n",
    "# mx_cmp_pb2core_nodes\n",
    "for node in range(mx_cmp_core_pb_graph_n):\n",
    "    # updated_node\n",
    "    mx_cmp_pb2core_nodes[node] = (\n",
    "        int(np.where(mx_cmp_core_pb_conn_graph_nodes == mx_cmp_pb2core_nodes[node])[0][0])\n",
    "    )\n",
    "\n",
    "# Update all original_node values with updated_node values for\n",
    "# mx_cmp_core_pb_graph_edges\n",
    "for edge in range(mx_cmp_core_pb_graph_m):\n",
    "    # updated_node\n",
    "    mx_cmp_core_pb_graph_edges[edge, 0] = (\n",
    "        int(np.where(mx_cmp_core_pb_graph_nodes == mx_cmp_core_pb_graph_edges[edge, 0])[0][0])\n",
    "    )\n",
    "    mx_cmp_core_pb_graph_edges[edge, 1] = (\n",
    "        int(np.where(mx_cmp_core_pb_graph_nodes == mx_cmp_core_pb_graph_edges[edge, 1])[0][0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preformatting continued\n",
    "# # Anti-degree of the core cross-linker nodes\n",
    "# core_nodes_anti_k = k*np.ones(n, dtype=int)\n",
    "# # Core cross-linker node active sites\n",
    "# core_nodes_active_sites = np.repeat(core_nodes, k)\n",
    "# core_nodes_active_sites_num = np.shape(core_nodes_active_sites)[0]\n",
    "\n",
    "# ####### Remove this dangling_chains array soon!\n",
    "# # Number of dangling chains on the core cross-linker nodes\n",
    "# core_nodes_dnglng_chns = np.zeros(n, dtype=int)\n",
    "# # Note that for multi-chain edges and self-loop chains, the graph object\n",
    "# # will provide that information on-demand\n",
    "\n",
    "# # Initialize random number generator\n",
    "# rng = np.random.default_rng()\n",
    "# # Initialize edge lists\n",
    "# core_pb_conn_edges = []\n",
    "# core_pb_edges = []\n",
    "\n",
    "# # Initialize node number integer constants\n",
    "# core_node_0 = 0\n",
    "# core_node_1 = 0\n",
    "# pb_node_0 = 0\n",
    "# pb_node_1 = 0\n",
    "\n",
    "# # Initialize number of chains and number of dangling chains in the\n",
    "# # network\n",
    "# m_dnglng = 0\n",
    "# m_ntwk = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Network topology initialization continues until either (1) all of the\n",
    "# # chains have been placed, i.e., m_ntwk = m, or (2) there are no more\n",
    "# # active sites, i.e., core_nodes_active_sites_num = 0\n",
    "\n",
    "# def core_node_update_func(\n",
    "#         core_node_updt: int,\n",
    "#         core_node_updt_active_site_indx: int,\n",
    "#         core_nodes_active_sites: np.ndarray,\n",
    "#         core_nodes_active_sites_num: int,\n",
    "#         core_nodes_anti_k: np.ndarray,\n",
    "#         core_nodes: np.ndarray,\n",
    "#         core2pb_nodes: list[np.ndarray],\n",
    "#         core_nodes_nghbrhd: list[np.ndarray],\n",
    "#         r_core_nodes_nghbrhd: list[np.ndarray]) -> tuple[np.ndarray, int, np.ndarray, np.ndarray, list[np.ndarray], list[np.ndarray]]:\n",
    "#     # Update inactive sites\n",
    "#     core_nodes_active_sites = np.delete(\n",
    "#         core_nodes_active_sites, core_node_updt_active_site_indx, axis=0)\n",
    "#     core_nodes_active_sites_num -= 1\n",
    "#     # Update anti-degree\n",
    "#     core_nodes_anti_k[core_node_updt] -= 1\n",
    "#     # Update sampling neighborhood list if the core cross-linker node\n",
    "#     # now has no more active sites\n",
    "#     if core_nodes_anti_k[core_node_updt] == 0:\n",
    "#         # Update sampling neighborhood list\n",
    "#         # Gather associated periodic boundary nodes\n",
    "#         pb_nodes_updt = core2pb_nodes[core_node_updt]\n",
    "#         for core_node in np.nditer(core_nodes):\n",
    "#             core_node = int(core_node)\n",
    "#             nghbr_nodes = core_nodes_nghbrhd[core_node]\n",
    "#             r_nghbr_nodes = r_core_nodes_nghbrhd[core_node]\n",
    "#             if np.shape(nghbr_nodes)[0] == 0: pass\n",
    "#             else:\n",
    "#                 # Address core node\n",
    "#                 core_node_updt_indx_arr = np.where(nghbr_nodes == core_node_updt)[0]\n",
    "#                 if np.shape(core_node_updt_indx_arr)[0] == 0: pass\n",
    "#                 else:\n",
    "#                     core_node_updt_indx = int(core_node_updt_indx_arr[0])\n",
    "#                     nghbr_nodes = np.delete(nghbr_nodes, core_node_updt_indx, axis=0)\n",
    "#                     r_nghbr_nodes = np.delete(r_nghbr_nodes, core_node_updt_indx, axis=0)\n",
    "#                 # Address all associated periodic boundary nodes\n",
    "#                 if np.shape(pb_nodes_updt)[0] == 0: pass\n",
    "#                 else:\n",
    "#                     for pb_node_updt in np.nditer(pb_nodes_updt):\n",
    "#                         pb_node_updt = int(pb_node_updt)\n",
    "#                         pb_node_updt_indx_arr = np.where(nghbr_nodes == pb_node_updt)[0]\n",
    "#                         if np.shape(pb_node_updt_indx_arr)[0] == 0: pass\n",
    "#                         else:\n",
    "#                             pb_node_updt_indx = int(pb_node_updt_indx_arr[0])\n",
    "#                             nghbr_nodes = np.delete(nghbr_nodes, pb_node_updt_indx, axis=0)\n",
    "#                             r_nghbr_nodes = np.delete(r_nghbr_nodes, pb_node_updt_indx, axis=0)\n",
    "#                 core_nodes_nghbrhd[core_node] = nghbr_nodes\n",
    "#                 r_core_nodes_nghbrhd[core_node] = r_nghbr_nodes\n",
    "    \n",
    "#     return (\n",
    "#         core_nodes_active_sites, core_nodes_active_sites_num, core_nodes_anti_k,\n",
    "#         core_nodes_nghbrhd, r_core_nodes_nghbrhd\n",
    "#     )\n",
    "\n",
    "# # Network topology initialization\n",
    "# while m_ntwk < m and core_nodes_active_sites_num > 0:\n",
    "#     # Assess if a chain-to-cross-link connection is forged for the\n",
    "#     # parent core cross-linker node\n",
    "#     if rng.random() > xi: continue\n",
    "#     else:\n",
    "#         # Randomly select an active site from the core nodes to\n",
    "#         # instantiate a chain\n",
    "#         core_node_0_active_site_indx = (\n",
    "#             rng.integers(np.shape(core_nodes_active_sites)[0], dtype=int)\n",
    "#         )\n",
    "#         core_node_0 = core_nodes_active_sites[core_node_0_active_site_indx]\n",
    "#         # Update inactive sites, anti-degree, active core cross-linker\n",
    "#         # nodes, and the sampling neighborhood list for the parent core\n",
    "#         # cross-linker node\n",
    "#         (core_nodes_active_sites, core_nodes_active_sites_num, core_nodes_anti_k,\n",
    "#          core_nodes_nghbrhd, r_core_nodes_nghbrhd) = core_node_update_func(\n",
    "#              core_node_0, core_node_0_active_site_indx, core_nodes_active_sites,\n",
    "#              core_nodes_active_sites_num, core_nodes_anti_k, core_nodes,\n",
    "#              core2pb_nodes, core_nodes_nghbrhd, r_core_nodes_nghbrhd)\n",
    "#         # Assess if a chain-to-cross-link connection is forged for a\n",
    "#         # neighbor cross-linker node\n",
    "#         if rng.random() > xi:\n",
    "#             # A dangling chain is formed\n",
    "#             core_nodes_dnglng_chns[core_node_0] += 1\n",
    "#             m_ntwk += 1\n",
    "#             m_dnglng += 1\n",
    "#             print(m_ntwk, core_nodes_active_sites_num, m_dnglng)\n",
    "#         else:\n",
    "#             # Extract sampling neighborhood about the core node\n",
    "#             nghbr_nodes = core_nodes_nghbrhd[core_node_0]\n",
    "#             r_nghbr_nodes = r_core_nodes_nghbrhd[core_node_0]\n",
    "#             # Check if the sampling neighborhood is empty\n",
    "#             if np.shape(nghbr_nodes)[0] == 0:\n",
    "#                 # A dangling chain is formed\n",
    "#                 core_nodes_dnglng_chns[core_node_0] += 1\n",
    "#                 m_ntwk += 1\n",
    "#                 m_dnglng += 1\n",
    "#                 print(m_ntwk, core_nodes_active_sites_num, m_dnglng)\n",
    "#             else:\n",
    "#                 # Calculate and normalize weighting factors\n",
    "#                 w_nghbrhd = np.exp(\n",
    "#                     ln_p_cnfrmtn_cubic_poly_fit_func(r_nghbr_nodes, *popt))\n",
    "#                 w_nghbrhd = w_nghbrhd / np.sum(w_nghbrhd, dtype=float)\n",
    "#                 # Randomly select a neighbor cross-linker node to host\n",
    "#                 # the other end of the chain\n",
    "#                 nghbr_node_1 = int(\n",
    "#                     rng.choice(nghbr_nodes, size=None, p=w_nghbrhd))\n",
    "#                 # Identify if the chain is a core edge or a periodic\n",
    "#                 # boundary edge\n",
    "#                 # Chain is a core edge\n",
    "#                 if nghbr_node_1 < n:\n",
    "#                     core_node_1 = nghbr_node_1\n",
    "#                     # Append chain to edge lists appropriately\n",
    "#                     core_pb_conn_edges.append((core_node_0, core_node_1))\n",
    "#                     core_pb_edges.append((core_node_0, core_node_1))\n",
    "#                 # Chain is a periodic edge\n",
    "#                 else:\n",
    "#                     pb_node_1 = nghbr_node_1\n",
    "#                     core_node_1 = pb2core_nodes[pb_node_1]\n",
    "#                     pb_nodes_0 = core2pb_nodes[core_node_0]\n",
    "#                     # Select the correct pb_node via the minimum image\n",
    "#                     # criterion, i.e., the minimum distance criterion\n",
    "#                     core_node_1_pstn = np.asarray(\n",
    "#                         [\n",
    "#                             core_pb_x[core_node_1],\n",
    "#                             core_pb_y[core_node_1]\n",
    "#                         ]\n",
    "#                     )\n",
    "#                     pb_nodes_0_num = np.shape(pb_nodes_0)[0]\n",
    "#                     r_pb_nodes_0 = np.empty(pb_nodes_0_num)\n",
    "#                     for pb_node_0_indx in range(pb_nodes_0_num):\n",
    "#                         pb_node_0_cnddt = pb_nodes_0[pb_node_0_indx]\n",
    "#                         pb_node_0_cnddt_pstn = np.asarray(\n",
    "#                             [\n",
    "#                                 core_pb_x[pb_node_0_cnddt],\n",
    "#                                 core_pb_y[pb_node_0_cnddt]\n",
    "#                             ]\n",
    "#                         )\n",
    "#                         r_pb_nodes_0[pb_node_0_indx] = (\n",
    "#                             np.linalg.norm(core_node_1_pstn-pb_node_0_cnddt_pstn)\n",
    "#                         )\n",
    "#                     pb_node_0 = pb_nodes_0[np.argmin(r_pb_nodes_0)]\n",
    "#                     # Append chain to edge lists appropriately\n",
    "#                     core_pb_conn_edges.append((core_node_0, core_node_1))\n",
    "#                     core_pb_edges.append((core_node_0, pb_node_1))\n",
    "#                     core_pb_edges.append((pb_node_0, core_node_1))\n",
    "#                 core_node_1_active_site_indx = int(\n",
    "#                     np.where(core_nodes_active_sites == core_node_1)[0][0])\n",
    "#                 # Update inactive sites, anti-degree, active core\n",
    "#                 # cross-linker nodes, and the sampling neighborhood list\n",
    "#                 # for the neighbor core cross-linker node\n",
    "#                 (core_nodes_active_sites, core_nodes_active_sites_num,\n",
    "#                  core_nodes_anti_k, core_nodes_nghbrhd,\n",
    "#                  r_core_nodes_nghbrhd) = core_node_update_func(\n",
    "#                      core_node_1, core_node_1_active_site_indx,\n",
    "#                      core_nodes_active_sites, core_nodes_active_sites_num,\n",
    "#                      core_nodes_anti_k, core_nodes, core2pb_nodes,\n",
    "#                      core_nodes_nghbrhd, r_core_nodes_nghbrhd)\n",
    "#                 m_ntwk += 1\n",
    "#                 print(m_ntwk, core_nodes_active_sites_num, m_dnglng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "\n",
    "# core_pb_conn_nodes = core_nodes.copy()\n",
    "\n",
    "# # Create nx.Graphs, and add nodes before edges\n",
    "# core_pb_graph = nx.Graph()\n",
    "# core_pb_graph.add_nodes_from(core_pb_nodes)\n",
    "# core_pb_graph.add_edges_from(core_pb_edges)\n",
    "\n",
    "# core_pb_conn_graph = nx.Graph()\n",
    "# core_pb_conn_graph.add_nodes_from(core_pb_conn_nodes)\n",
    "# core_pb_conn_graph.add_edges_from(core_pb_conn_edges)\n",
    "\n",
    "# # Isolate largest/maximum connected component from the\n",
    "# # core_pb_conn_graph in a nodewise fashion. Note that\n",
    "# # mx_cmp_core_pb_conn_graph_nodes[updated_node] = original_node\n",
    "# mx_cmp_core_pb_conn_graph_nodes = max(\n",
    "#     nx.connected_components(core_pb_conn_graph), key=len)\n",
    "# mx_cmp_core_pb_conn_graph = (\n",
    "#     core_pb_conn_graph.subgraph(mx_cmp_core_pb_conn_graph_nodes).copy()\n",
    "# )\n",
    "# # Nodes from the core_pb_conn_graph largest/maximum connected\n",
    "# # component, sorted in ascending order\n",
    "# mx_cmp_core_pb_conn_graph_nodes = (\n",
    "#     np.sort(np.fromiter(mx_cmp_core_pb_conn_graph_nodes, dtype=int))\n",
    "# )\n",
    "# # Edges from the core_pb_conn_graph largest/maximum connected\n",
    "# # component\n",
    "# mx_cmp_core_pb_conn_graph_edges = (\n",
    "#     np.asarray(list(mx_cmp_core_pb_conn_graph.edges()), dtype=int)\n",
    "# )\n",
    "# # Number of nodes in the core_pb_conn_graph largest/maximum\n",
    "# # connected component\n",
    "# mx_cmp_core_pb_conn_graph_n = (\n",
    "#     np.shape(mx_cmp_core_pb_conn_graph_nodes)[0]\n",
    "# )\n",
    "# # Number of edges in the core_pb_conn_graph largest/maximum\n",
    "# # connected component\n",
    "# mx_cmp_core_pb_conn_graph_m = (\n",
    "#     np.shape(mx_cmp_core_pb_conn_graph_edges)[0]\n",
    "# )\n",
    "\n",
    "# # Isolate largest/maximum connected component from the\n",
    "# # core_pb_graph via the core_pb_conn_graph largest/maximum\n",
    "# # connected component\n",
    "# mx_cmp_core_pb_graph_nodes = []\n",
    "# mx_cmp_core_pb_graph_edges = []\n",
    "\n",
    "# for edge in range(mx_cmp_core_pb_conn_graph_m):\n",
    "#     # original_node\n",
    "#     core_node_0 = mx_cmp_core_pb_conn_graph_edges[edge, 0]\n",
    "#     core_node_1 = mx_cmp_core_pb_conn_graph_edges[edge, 1]\n",
    "\n",
    "#     # Add edge(s) in the core_pb_graph\n",
    "#     if core_pb_graph.has_edge(core_node_0, core_node_1):\n",
    "#         # Add edge that connects two core cross-linkers in the\n",
    "#         # core_pb_graph, and add the core cross-linkers\n",
    "#         mx_cmp_core_pb_graph_nodes.append(core_node_0)\n",
    "#         mx_cmp_core_pb_graph_nodes.append(core_node_1)\n",
    "#         mx_cmp_core_pb_graph_edges.append((core_node_0, core_node_1))\n",
    "#     else:\n",
    "#         # Add two edges that each separately yet correspondingly\n",
    "#         # connect a core cross-linker and a periodic boundary\n",
    "#         # cross-linker in the core_pb_graph. Also add the core\n",
    "#         # and periodic boundary cross-linkers. Identify all\n",
    "#         # possible periodic boundary cross-linkers that could be\n",
    "#         # involved in each edge.\n",
    "#         pb_nodes_0 = core2pb_nodes[core_node_0]\n",
    "#         pb_nodes_1 = core2pb_nodes[core_node_1]\n",
    "#         # Determine the specific periodic boundary and core\n",
    "#         # cross-linker pair involved in each edge, and then add\n",
    "#         # the edge and cross-linkers\n",
    "#         for pb_node_0 in np.nditer(pb_nodes_0):\n",
    "#             pb_node_0 = int(pb_node_0)\n",
    "#             if core_pb_graph.has_edge(pb_node_0, core_node_1):\n",
    "#                 mx_cmp_core_pb_graph_nodes.append(pb_node_0)\n",
    "#                 mx_cmp_core_pb_graph_nodes.append(core_node_1)\n",
    "#                 mx_cmp_core_pb_graph_edges.append((pb_node_0, core_node_1))\n",
    "#                 break\n",
    "#             else: pass\n",
    "#         for pb_node_1 in np.nditer(pb_nodes_1):\n",
    "#             pb_node_1 = int(pb_node_1)\n",
    "#             if core_pb_graph.has_edge(core_node_0, pb_node_1):\n",
    "#                 mx_cmp_core_pb_graph_nodes.append(core_node_0)\n",
    "#                 mx_cmp_core_pb_graph_nodes.append(pb_node_1)\n",
    "#                 mx_cmp_core_pb_graph_edges.append((core_node_0, pb_node_1))\n",
    "#                 break\n",
    "#             else: pass\n",
    "\n",
    "# # Convert to np.ndarrays and retain unique values\n",
    "# mx_cmp_core_pb_graph_nodes = (\n",
    "#     np.unique(np.asarray(mx_cmp_core_pb_graph_nodes, dtype=int))\n",
    "# )\n",
    "# mx_cmp_core_pb_graph_edges = (\n",
    "#     np.unique(np.asarray(mx_cmp_core_pb_graph_edges, dtype=int), axis=0)\n",
    "# )\n",
    "# # Number of nodes in the core_pb_graph largest/maximum connected\n",
    "# # component\n",
    "# mx_cmp_core_pb_graph_n = np.shape(mx_cmp_core_pb_graph_nodes)[0]\n",
    "# # Number of edges in the core_pb_graph largest/maximum connected\n",
    "# # component\n",
    "# mx_cmp_core_pb_graph_m = np.shape(mx_cmp_core_pb_graph_edges)[0]\n",
    "\n",
    "# # Isolate the cross-linker coordinates for the largest/maximum\n",
    "# # connected component\n",
    "# # updated_node\n",
    "# mx_cmp_core_pb_x = core_pb_x[mx_cmp_core_pb_graph_nodes]\n",
    "# mx_cmp_core_pb_y = core_pb_y[mx_cmp_core_pb_graph_nodes]\n",
    "# # if dim == 3:\n",
    "# #     mx_cmp_core_pb_z = core_pb_z[mx_cmp_core_pb_graph_nodes]\n",
    "\n",
    "# # Isolate pb2core_nodes for the largest/maximum connected\n",
    "# # component. Note that\n",
    "# # mx_cmp_pb2core_nodes[updated_node] = original_node\n",
    "# mx_cmp_pb2core_nodes = pb2core_nodes[mx_cmp_core_pb_graph_nodes]\n",
    "\n",
    "# # Update all original_node values with updated_node values for\n",
    "# # mx_cmp_core_pb_conn_graph_edges\n",
    "# for edge in range(mx_cmp_core_pb_conn_graph_m):\n",
    "#     # updated_node\n",
    "#     mx_cmp_core_pb_conn_graph_edges[edge, 0] = (\n",
    "#         int(np.where(mx_cmp_core_pb_conn_graph_nodes == mx_cmp_core_pb_conn_graph_edges[edge, 0])[0][0])\n",
    "#     )\n",
    "#     mx_cmp_core_pb_conn_graph_edges[edge, 1] = (\n",
    "#         int(np.where(mx_cmp_core_pb_conn_graph_nodes == mx_cmp_core_pb_conn_graph_edges[edge, 1])[0][0])\n",
    "#     )\n",
    "\n",
    "# # Update all original_node values with updated_node values for\n",
    "# # mx_cmp_pb2core_nodes\n",
    "# for node in range(mx_cmp_core_pb_graph_n):\n",
    "#     # updated_node\n",
    "#     mx_cmp_pb2core_nodes[node] = (\n",
    "#         int(np.where(mx_cmp_core_pb_conn_graph_nodes == mx_cmp_pb2core_nodes[node])[0][0])\n",
    "#     )\n",
    "\n",
    "# # Update all original_node values with updated_node values for\n",
    "# # mx_cmp_core_pb_graph_edges\n",
    "# for edge in range(mx_cmp_core_pb_graph_m):\n",
    "#     # updated_node\n",
    "#     mx_cmp_core_pb_graph_edges[edge, 0] = (\n",
    "#         int(np.where(mx_cmp_core_pb_graph_nodes == mx_cmp_core_pb_graph_edges[edge, 0])[0][0])\n",
    "#     )\n",
    "#     mx_cmp_core_pb_graph_edges[edge, 1] = (\n",
    "#         int(np.where(mx_cmp_core_pb_graph_nodes == mx_cmp_core_pb_graph_edges[edge, 1])[0][0])\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heterogeneous_spatial_networks_funcs import m_arg_stoich_func, n_nu_arg_m_func, n_tot_arg_n_func, f_arg_n_func\n",
    "\n",
    "f_n_arr = np.empty(sample_num)\n",
    "\n",
    "for sample in range(sample_num):\n",
    "    k = params_arr[sample, 4]\n",
    "    n = params_arr[sample, 5]\n",
    "    nu = params_arr[sample, 6]\n",
    "    m = m_arg_stoich_func(n, k)\n",
    "    n_nu = n_nu_arg_m_func(m, nu)\n",
    "    n_tot = n_tot_arg_n_func(n_nu, n)\n",
    "    f_n_arr[sample] = f_arg_n_func(n, n_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00047596382674916705\n",
      "0.11764705882352941\n"
     ]
    }
   ],
   "source": [
    "print(np.min(f_n_arr))\n",
    "print(np.max(f_n_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heterogeneous_spatial_networks_funcs import m_arg_stoich_func, n_nu_arg_m_func, L_arg_rho_func\n",
    "\n",
    "L_arr = np.empty(sample_num)\n",
    "\n",
    "for sample in range(sample_num):\n",
    "    dim = params_arr[sample, 0]\n",
    "    rho_nu = params_arr[sample, 3]\n",
    "    k = params_arr[sample, 4]\n",
    "    n = params_arr[sample, 5]\n",
    "    nu = params_arr[sample, 6]\n",
    "    m = m_arg_stoich_func(n, k)\n",
    "    n_nu = n_nu_arg_m_func(m, nu)\n",
    "    L_arr[sample] = L_arg_rho_func(dim, n_nu, rho_nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b_arr[0]\n",
    "\n",
    "l_nghbrhd_arr = np.empty(sample_num)\n",
    "\n",
    "for sample in range(sample_num):\n",
    "    nu = params_arr[sample, 6]\n",
    "    r_nghbrhd = nu * b\n",
    "    L = L_arr[sample]\n",
    "    l_nghbrhd_arr[sample] = r_nghbrhd / L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0206155281280883\n",
      "11.602424681415384\n"
     ]
    }
   ],
   "source": [
    "print(np.min(l_nghbrhd_arr))\n",
    "print(np.max(l_nghbrhd_arr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3123",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
